{"meta":{"title":"萧爽楼|李东东的安静一隅","subtitle":"李东东的安静一隅","description":"博客叫萧爽楼，从《浮生六记》中借来的名字。身边，很难寻找古人春游、结社、集会之乐趣。只愿文字在这个小小的空间里仍然能够发挥古老的力量。博客的内容主要包括个人的生活、读书感想，也包括数学、互联网、编程语言、科学计算等方面的学习侧记。","author":"ddlee","url":"http://blog.ddlee.cn"},"pages":[{"title":"About","date":"2016-07-30T13:19:00.000Z","updated":"2017-05-26T13:36:57.608Z","comments":true,"path":"About/index.html","permalink":"http://blog.ddlee.cn/About/index.html","excerpt":"","text":"呦呦鹿鸣，食野之苹。我有嘉宾，鼓瑟吹笙。 每个人都有隐藏的一隅。 一个人，安静下来，想一些没那么重要又如此重要的一些人，做一些喜欢又没那么喜欢的事儿，在烦恼与忙碌终于远去的时光的罅隙里。 有人说，照片是凝固了的时光。所以很多人着迷于摄影，用镜头记录想要回味和分享的瞬间。 有人说，凝固了的时光不好，流动的时光才有趣。所以每天拍一段几秒的视频，过个三年五载，再将它们串联起来，像串珍珠那样。 而我觉得，文字记录的时光，却是每时每刻都与现在流淌着的日子融合了的。 每次重读一行行文字，便是一趟联接着当下、过去，还有未来的心灵旅程。 文字太模糊了，不足以让你记起全部的细节，你只好亲自走回去，回到青葱的岁月，像看故事里的人物那样看看那时的自己； 文字又太准确了，这些陌生又熟悉的字眼，这些亲切又早已忘却的句子，就像当年的自己把故事亲口哼唱给你听，此时此刻，恰如彼时彼刻。 文字脆弱，却又力量无穷。 关于博客博客叫萧爽楼，从《浮生六记》中借来的名字。身边，很难寻找古人春游、结社、集会之乐趣。只愿文字在这个小小的空间里仍然能够发挥古老的力量。 博客的内容主要包括个人的生活、读书感想，也包括数学、互联网、编程语言、科学计算等方面的学习侧记。 关于我我现在在同济念书，学的是数学。对统计学习、数据分析、传播学、个人管理等感兴趣。摄影控，喜欢游泳和长跑。 我非常崇敬古代文人的这一人生理想： 为天地立心 为生民立命 为往圣续绝学 为万世开太平 在这里(右击复制RSS源)订阅我的博客。 更多关于我的情况请访问我的主页"}],"posts":[{"title":"[论文笔记]Accurate, Large Minibatch SGD: Training ImageNet in One Hour","slug":"论文笔记-Accurate-Large-Minibatch-SGD-Training-ImageNet-in-One-Hour","date":"2017-06-14T14:43:41.000Z","updated":"2017-06-14T15:23:44.849Z","comments":true,"path":"2017/06/14/论文笔记-Accurate-Large-Minibatch-SGD-Training-ImageNet-in-One-Hour/","link":"","permalink":"http://blog.ddlee.cn/2017/06/14/论文笔记-Accurate-Large-Minibatch-SGD-Training-ImageNet-in-One-Hour/","excerpt":"","text":"论文：Accurate, Large Minibatch SGD: Training ImageNet in One Hour 这篇文章在各处都有很广泛的讨论，作为实验经验并不多的小白，将文中tricks只做些记录。 Linear Scaling Rule进行大批量的Minibatch SGD时会有批量越大，误差越大的问题。本文提出的Linear Scaling Rule正是试图解决这一问题。 Motivation设想两个情景：一是在一次参数更新中使用kn个样本梯度，二是分为k次更新，每次取n个样本梯度。 第一种情景的参数更新公式： $$w_t+1^{(1)} = w_t^{(1)} - \\mu^{(1)} \\frac{1}{kn} \\sum_{j \\leq k} \\sum \\bigtriangledown l(x, w_t)$$ 第二种情景的参数更新公式： $$w_t+k^{(2)} = w_t^{(2)} - \\mu^{(2)} \\frac{1}{n} \\sum_{j \\leq k} \\sum \\bigtriangledown l(x, w_t+j)$$ 由上面可以看出，主要的区别是梯度平均时批量的大小不同，前者为kn，后者为每次n，更新k次。 再假设双重求和号内项变化不大时，为使情景二更新k次（即使用同样数量的样本）之后参数与情景一类似，我们自然要将学习速率$\\mu$线性提升。 Gradual Warmup上面提到的Linear Scaling Rule使用的假设是梯度变化不大。但在训练初期，参数随机初始化，梯度变化很大，因而Linear Scaling Rule不再适用。在实践中，可以使学习速率在初始时较小，在经过几个epoch训练后再升至与kn批量相应的大小。 BN statistics在分布式训练的系统中，对于BN中要估计的均值和方差，文中给出的建议是对所有worker上的样本计算均值和方差，而不是每个worker单独计算。 Weight Decay由于weight decay的存在，Linear Scaling Rule最好用于学习速率，而非用于Loss Function Momentum Correction加入Linear Scaling Rule之后，适用动量加速的SGD需要进行动量更正。 Data Shuffling在分布式的系统中，先进行Data Shuffling，再分配数据到每个worker上。","categories":[{"name":"Papers","slug":"Papers","permalink":"http://blog.ddlee.cn/categories/Papers/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://blog.ddlee.cn/tags/AI/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://blog.ddlee.cn/tags/Deep-Learning/"},{"name":"Papers","slug":"Papers","permalink":"http://blog.ddlee.cn/tags/Papers/"}]},{"title":"自用LaTeX中英文简历模板","slug":"自用LaTeX中英文建立模板","date":"2017-06-14T10:58:41.000Z","updated":"2017-06-14T10:58:41.185Z","comments":true,"path":"2017/06/14/自用LaTeX中英文建立模板/","link":"","permalink":"http://blog.ddlee.cn/2017/06/14/自用LaTeX中英文建立模板/","excerpt":"","text":"分享一套自用的LaTeX中英文简历模板，改编自Alessandro Plasmati在ShareLaTeX上分享的模板。 使用 Github仓库：ddlee96/latex_cv_template 编译引擎： XeLaTeX 下载地址： v0.1 压缩包内包含.tex文件和所用字体文件，解压后修改.tex文件再编译即可。 在Ubuntu 16.04, Texlive 2016环境下测试通过。 英文字体: Fontin，中文字体：方正兰亭黑 协议 .tex代码：Apache 2.0 字体： 仅供个人使用 效果预览英文 中文","categories":[{"name":"Individual Development","slug":"Individual-Development","permalink":"http://blog.ddlee.cn/categories/Individual-Development/"}],"tags":[{"name":"Individual Development","slug":"Individual-Development","permalink":"http://blog.ddlee.cn/tags/Individual-Development/"},{"name":"LaTeX","slug":"LaTeX","permalink":"http://blog.ddlee.cn/tags/LaTeX/"}]},{"title":"[论文笔记]On the Effects and Weight Normalization in GAN","slug":"论文笔记-On-the-Effects-and-Weight-Normalization-in-GAN","date":"2017-06-10T14:01:21.000Z","updated":"2017-06-14T14:57:42.981Z","comments":true,"path":"2017/06/10/论文笔记-On-the-Effects-and-Weight-Normalization-in-GAN/","link":"","permalink":"http://blog.ddlee.cn/2017/06/10/论文笔记-On-the-Effects-and-Weight-Normalization-in-GAN/","excerpt":"","text":"论文：On the Effects and Weight Normalization in GAN 本文探索了参数标准化(Weight Normalization)这一技术在GAN中的应用。BN在mini-batch的层级上计算均值和方差，容易引入噪声，并不适用于GAN这种生成模型，而WN对参数进行重写，引入噪声更少。 我觉得本文的亮点有二： 1. 提出T-ReLU并配合Affine Tranformation使在引入WN后网络的表达能力维持不变朴素的参数标准化层有如下的形式： $$y=\\frac{{w}^{T}x}{\\|w\\|}$$ 文中称这样形式的层为“strict weight-normalized layer”。若将线性层换为这样的层，网络的表达能力会下降，因而需要添加如下的affine transformation: $$y=\\frac{{w}^{T}x}{\\|w\\|} \\gamma + \\beta$$ 用于恢复网络的表达能力。 将上述变换带入ReLU，简化后可以得到如下T-ReLu: TReLU_\\alpha (x) = ReLU(x-\\alpha) + \\alpha文章的一个重要结论是，在网络的最后一层加入affine transformation层之后，堆叠的“线性层+ReLU”与“strict weight-normalized layer + T-ReLU”表达能力相同（在附录中给出证明）。 下面L表示线性层，R表示ReLU，TR表示TReLU，A表示affine transformation，S表示上述的strict weight-normalized layer。 证明的大致思路是，在ReLU与线性层之间加入affine transformation层，由于线性层的存在，affine transformation带来的效果会被吸收（相当于多个线性层叠在一起还是线性层），网络表达能力不变。而”L+R+A”的结构可以等价于”S+TR+A”。如此递归下去，即可得到结论。个人认为相当于把线性层中的bias转嫁成了TReLU中的threshold（即$\\alpha$）。 2. 提出对生成图形的评估指标生成式模型的生成效果常常难以评价。DcGAN给出的结果也是生成图片的对比。本文中提出一个评价生成效果的指标，且与人的主观评价一致。 评价的具体指标是生成图片与测试集图片的欧氏距离，评价的对象是生成器是Generator。有如下形式： $$\\frac{1}{m} \\sum_{i=1}^{m} min_z {\\|G(z)-x^{(i)}\\|}^2$$ 其中的$min$指使用梯度下降方法等使生成图片的效果最好。但事实上这样做开销很高。 PyTorch实现作者将他们的实现代码公布在了GitHub上。 下面是利用PyTorch对T-ReLU的实现： class TPReLU(Module): def __init__(self, num_parameters=1, init=0.25): self.num_parameters = num_parameters super(TPReLU, self).__init__() self.weight = Parameter(torch.Tensor(num_parameters).fill_(init)) self.bias = Parameter(torch.zeros(num_parameters)) def forward(self, input): bias_resize = self.bias.view(1, self.num_parameters, *((1,) * (input.dim() - 2))).expand_as(input) return F.prelu(input - bias_resize, self.weight.clamp(0, 1)) + bias_resize 对 Weigh-normalized layer 的实现： class WeightNormalizedLinear(Module): def __init__(self, in_features, out_features, scale=True, bias=True, init_factor=1, init_scale=1): super(WeightNormalizedLinear, self).__init__() self.in_features = in_features self.out_features = out_features self.weight = Parameter(torch.Tensor(out_features, in_features)) if bias: self.bias = Parameter(torch.zeros(1, out_features)) else: self.register_parameter('bias', None) if scale: self.scale = Parameter(torch.Tensor(1, out_features).fill_(init_scale)) else: self.register_parameter('scale', None) self.reset_parameters(init_factor) def reset_parameters(self, factor): stdv = 1. * factor / math.sqrt(self.weight.size(1)) self.weight.data.uniform_(-stdv, stdv) if self.bias is not None: self.bias.data.uniform_(-stdv, stdv) def weight_norm(self): return self.weight.pow(2).sum(1).add(1e-6).sqrt() def norm_scale_bias(self, input): output = input.div(self.weight_norm().transpose(0, 1).expand_as(input)) if self.scale is not None: output = output.mul(self.scale.expand_as(input)) if self.bias is not None: output = output.add(self.bias.expand_as(input)) return output def forward(self, input): return self.norm_scale_bias(F.linear(input, self.weight)) 观察上面的forward函数可以发现，TReLU添加bias这一习得参数，而weight-normalized layer中则对传入的weight进行了标准化。","categories":[{"name":"Papers","slug":"Papers","permalink":"http://blog.ddlee.cn/categories/Papers/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://blog.ddlee.cn/tags/AI/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://blog.ddlee.cn/tags/Deep-Learning/"},{"name":"Papers","slug":"Papers","permalink":"http://blog.ddlee.cn/tags/Papers/"},{"name":"GAN","slug":"GAN","permalink":"http://blog.ddlee.cn/tags/GAN/"}]},{"title":"[论文笔记]Large-Scale Evolution of Image Classifiers","slug":"论文笔记-Large-Scale-Evolution-of-Image-Classifiers","date":"2017-06-05T08:09:52.000Z","updated":"2017-06-05T08:09:52.667Z","comments":true,"path":"2017/06/05/论文笔记-Large-Scale-Evolution-of-Image-Classifiers/","link":"","permalink":"http://blog.ddlee.cn/2017/06/05/论文笔记-Large-Scale-Evolution-of-Image-Classifiers/","excerpt":"","text":"论文：Large-Scale Evolution of Image, Classifiers Abstract深层网络在图片分类问题上表现优异，但网络结构的设计上并没有统一的指导。进化是构建深度网络架构的一种方式。利用本文的自动化方法得出的深度网络结构，已经能在CIFAR-10上取得可以跟人工设计的网络相媲美的结果 MethodsEvolution Algorithm整个算法的核心是如下的tournament selection: population: 供筛选的群体 individual: 个体，带有指标fitness，特别地，指在CV集上的损失 worker: 筛选者，上帝 population 中的 individual 均已在训练集上训练完毕，带有指标 fitness worker 随机选择一对 individual，比较 fitness，较差的 individual 被舍弃 表现较好的 individual 成为parent，对其施加 mutation (变异)，得到 child 训练 child 并在CV集上得到其 fitness，归还到 population 中 Encoding and Mutation个体的网络结构和部分参数被编码为DNA。 能够施加的变异有： 改变学习率 恒等（不变） 重设参数 加入卷积层 移除卷积层 更改卷积层的stride参数 更改卷积层的Channel参数 更改卷积核大小 加入skip连接（类似ResNet) 移除skip连接 Computation计算方面采用了并行、异步、无锁的策略。 建立约为 population 数1/4的 worker，分别运行于不同的机器上，之间独立异步。population 共享，若两个 worker 在一个 individual 上产生冲突，则后一个 worker 停止并等待再次尝试。 Weight Inheritance除了架构之外，子模型还会继承父母模型未经变异影响的隐藏层参数（不仅是DNA中的），这样使子模型的训练时间大幅减小。 Experiments and Results文章的主要结果如下图： 最右边的结构是在CIFAR-10上发现的最好（CV集准确度最高）的结构，左边两个是它的祖先。其中白色块相当于简单的线性层，彩色块则带有非线性激活，可以看到，不同于人工设计的网络，某一线性层之后可能包含多个非线性层。 另外，利用本文的模型，也在CIFAR-100上做了实验，可以达到76.3%的准确率，一定程度上说明了算法的扩展性。 Analysis 上图说明随着 population 规模和训练步数的增加，模型的整体水平在变好。 在模型陷入局部最优值时，提高变异率和重设参数会使群体继续进化。这是由于变异中包含恒等映射等不改变模型架构的变异类型，再加上weight Inheritance，一些子模型只是训练次数比其他模型多很多的“活化石”。 小结Google I/O时就提到了自动筛选最优网络结构，但没有公布论文。但将网络结构自动化，必定是未来的方向。个人认为，ResNet就相当于自动化网络深度（一些层实际上被跳过了），而Inception单元似乎包含了太多的先验，而且也没有逻辑上的证据说明这样的结构更有效。网络结构本身就是先验信息，而要达到通用的人工智能，这些先验也必须由模型自行发觉。 强化学习本身也是一个进化过程，应该也有相关的工作将强化学习的框架应用于网络结构的学习上。 更进一步地，若数据是一阶信息，深度网络的隐藏层学到的表示是二阶信息，深度网络的结构则是三阶信息，从一阶到二阶的框架是不是都可以移植到二阶到三阶上来？关键之处在于我们还没有描述好深度网络的结构空间，但就现在的发展看，深度网络的一些基本结构(conv, BN)等，已经被作为基本单元（离散的）来进行构建和筛选了，也就是说，所有深度网络构成的空间之性质如何，还有大量的工作可以做。","categories":[{"name":"Papers","slug":"Papers","permalink":"http://blog.ddlee.cn/categories/Papers/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://blog.ddlee.cn/tags/AI/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://blog.ddlee.cn/tags/Deep-Learning/"},{"name":"Papers","slug":"Papers","permalink":"http://blog.ddlee.cn/tags/Papers/"},{"name":"autoML","slug":"autoML","permalink":"http://blog.ddlee.cn/tags/autoML/"}]},{"title":"[论文笔记]An Analysis of Deep Neural Network Models for Practical Applications","slug":"论文笔记-An-Analysis-of-Deep-Neural-Network-Models-for-Practical-Applications","date":"2017-06-03T06:27:07.000Z","updated":"2017-06-03T06:27:07.962Z","comments":true,"path":"2017/06/03/论文笔记-An-Analysis-of-Deep-Neural-Network-Models-for-Practical-Applications/","link":"","permalink":"http://blog.ddlee.cn/2017/06/03/论文笔记-An-Analysis-of-Deep-Neural-Network-Models-for-Practical-Applications/","excerpt":"","text":"论文：An Analysis of Deep Neural Network Models for Practical Applications 本文是对现有（论文发表于2016年5月）深度网络的比较，从以下方面入手： accuracy memory footprint parameters operations count inference time power consumption 以下图片各模型的着色是统一的：蓝色是Inception系，绿色是VGG系，粉色是ResNet系，黄色为AlexNet系。 上图是Top1准确率与模型参数数、操作数的关系。可以看到Inception系列网络以较少的参数取得相对高的准确率，而VGG系则在这一点上表现很差。 上面两图分别是推断耗时和电量消耗与批量大小的关系。可以看到，两者均与批量大小无明显的相关关系。但电量消耗在不同的模型之间也非常类似，而推断时间与模型结构关系很大（VGG再次尴尬）。 上图展示了模型占用内存大小与批量大小的关系，大部分网络都有相对固定的内存占用，随后随批量大小的上扬而上涨。 从上图可以发现推断耗时和模型的操作数大体上呈现线性关系。 电量消耗与模型的参数数、操作数并没有明显的相关性。 注意，上图中点的大小代表模型操作数，横轴代表推断效率，纵轴表示准确率。灰色区域表示模型获得了额外的推断效率或准确率，而白色区域代表非最优。 操作数越多的模型推断效率越低，大部分模型都落在相对平衡的边界上，VGG和小批量情形下的AlexNet落在了非最优区域。 小结从这篇论文的比较中可以看到，在特定的任务中对网络特定结构的设计（如Inception单元），即加入更强的先验知识，比堆叠网络层数更有效。深度网络还是需要人类的指导才能发挥更大的作用。","categories":[{"name":"Papers","slug":"Papers","permalink":"http://blog.ddlee.cn/categories/Papers/"}],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://blog.ddlee.cn/tags/Deep-Learning/"},{"name":"Papers","slug":"Papers","permalink":"http://blog.ddlee.cn/tags/Papers/"},{"name":"Neural Network","slug":"Neural-Network","permalink":"http://blog.ddlee.cn/tags/Neural-Network/"}]},{"title":"深度学习和分布式表示","slug":"深度学习和分布式表示","date":"2017-06-01T14:52:16.000Z","updated":"2017-06-03T04:29:31.304Z","comments":true,"path":"2017/06/01/深度学习和分布式表示/","link":"","permalink":"http://blog.ddlee.cn/2017/06/01/深度学习和分布式表示/","excerpt":"","text":"本文的两个主要参考资料： Yoshua Bengio在2016年九月Deep Learning School的演讲Foundations and Challenges of Deep Learning。YouTube Deep Learning, Goodfellow et al, Section 15.4 从机器学习到人工智能在演讲中，Bengio提到从机器学习到人工智能有五个关键的飞跃： Lots of data Very flexible models Enough computing power Powerful priors that can defeat the curse of dimensionality Computationally efficient inference 第一点已经发生，到处都提大数据，到处都在招数据分析师。我在读高中时，就曾预感数据将是新时代的石油和煤炭，因为数据正是人类社会经验的总结，数据带来的知识和见解将在驱动社会进步中发挥越来越重要的作用，而自己要立志成为新时代的矿工。 第二点在我看来有两个例子，一是核技巧，通过核函数对分布空间的转换，赋予了模型更强大的表述能力；二是深度神经网络，多层的框架和非线性的引入使得模型理论上可以拟合任意函数。 第三点，借云计算的浪潮，计算力不再是一项资产而是一项可供消费的服务，我们学生也可以廉价地接触到根本负担不起的计算力资源。而GPU等芯片技术的进步也为AI的浩浩征程添砖加瓦。 第五点，近期发布的Tensorflow Lite和Caffe2等工具也有助于越来越多地将计算任务分配在终端上进行，而非作为一个发送与接收器。 最后第四点，也是这篇文章的中心话题：借助分布式表示的强大能力，深度学习正尝试解决维度带来的灾难。 没有免费的午餐简单说，没有免费的午餐定理指出找不到一个在任何问题上都表现最优的模型/算法。不同的模型都有其擅长的问题，这由该模型建立时引入的先验知识决定。 那么，深度学习加入的先验知识是什么？ Bengio用的词是Compositionality，即复合性，某一概念之意义由其组成部分的意义以及组合规则决定。复合性的原则可以用于高效地描述我们的世界，而深度学习模型中隐藏的层正是去学习其组成部分，网络的结构则代表了组合规则。这正是深度学习模型潜在的信念。 分布式表示带来的指数增益分布式表示(Distributed Representation)是连接主义的核心概念，与复合性的原理相合。整体由组成它的个体及其组合来表示。请看下面的例子： 描述一个形状，我们将其分解为不同的特征来表述。分布式表示是一种解耦，它试图复杂的概念分离成独立的部分。而这也引出了分布式表示带来的缺点：隐藏层学到的分解特征难以得到显式的解释。 传统的机器学习算法，如K-Means聚类、决策树等，大多使用的是非分布式表示，即用特定的参数去描述特定的区域。如K-Means聚类，我们要划分多少区域，就需要有多少个中心点。因而，这类算法的特点是，随着参数个数的提升，其能描述的概念线性增长。 使用分布式表示的深度网络，则可以享受到指数级的增益，即，随着参数个数的提升，其表述能力是指数级的增长。具有$k$个值的$n$个特征，可以描述${k}^{n}$个不同的概念。 分布式表示在泛化上的优势分布式的想法还可以得到额外的泛化优势。通过重新组合在原有数据中抽离出来的特征，可以表示得到原有数据中不存在的实例。在Radford et al.的工作中，生成模型区习得了性别，并能从“戴眼镜的男人”-“男人”+“女人”=“戴眼镜的女人”这样的抽象概念表达式中生成实例。 分布式表示与巻积神经网络巻积神经网络不同的滤波器习得的特征可以为分布式表示的概念分解这一特性提供一些例子。下图是VGG16不同滤波器得到结果的可视化表示，出自Francois Chollet的博文How convolutional neural networks see the world 可以看到，浅层的滤波器学到的是简单的颜色、线条走向等特征，较深的滤波器学到复杂的纹理。 量子计算机与分布式表示在我看来，量子计算机的激动人心之处也在于其表示能力。一个量子态可以表示原先两个静态表示的信息，原先需要8个单位静态存储表示的信息只需要3个量子态单位即可表示，这也是指数级的增益。在这一点上，计算模型和概念模型已然殊途同归。 小结从经验中总结原则，用原则生成套路，正是我们自己处理和解决新问题的途径。通过解耦得到的信息来消除未知和不确定性，是我们智能的一部分。我们眼中的世界，只是适合我们的一种表示而已。也许，真正的人工智能到来那一刻，会是我们创造的机器“理解”了自己的表示系统之时——我们所关注的可解释性，也就无关紧要了。","categories":[{"name":"AI","slug":"AI","permalink":"http://blog.ddlee.cn/categories/AI/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://blog.ddlee.cn/tags/AI/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://blog.ddlee.cn/tags/Deep-Learning/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://blog.ddlee.cn/tags/Machine-Learning/"}]},{"title":"[论文笔记]On-the-fly Operation Batching in Dynamic Computation Graphs","slug":"论文笔记-On-the-fly-Operation-Batching-in-Dynamic-Computation-Graphs","date":"2017-05-30T07:24:34.000Z","updated":"2017-05-30T07:24:34.453Z","comments":true,"path":"2017/05/30/论文笔记-On-the-fly-Operation-Batching-in-Dynamic-Computation-Graphs/","link":"","permalink":"http://blog.ddlee.cn/2017/05/30/论文笔记-On-the-fly-Operation-Batching-in-Dynamic-Computation-Graphs/","excerpt":"","text":"论文：On-the-fly Operation Batching in Dynamic Computaion Graphs 背景基于动态图的深度学习框架如Pytorch,DyNet提供了更为灵活的结构和数据维度的选择，但要求开发者自行将数据批量化，才能最大限度地发挥框架的并行计算优势。 当前的状况：灵活的结构与高效计算左图为循环结构，右图将序列补齐，批量化 灵活的结构和数据输入维度，采用朴素的循环结构实现，但不高效，因为尽管维度不同，在循环内数据接受的是同样的操作。 对数据做“Padding”，即用傀儡数据将输入维度对齐，进而实现向量化，但这种操作对开发者并不友好，会使开发者浪费掉很多本该投入到结构设计等方面的精力。 本文提出的方法三个部分 Graph Definition Operation Batching Computation 第一步和第三步在当前已被大部分深度学习框架较好地实现。主要特点是，构建计算图与计算的分离，即”Lazy Evaluation”。比如在Tensorflow中，一个抽象层负责解析计算图各节点之间的依赖，决定执行计算的顺序，而另一个抽象层则负责分配计算资源。 Operation BatchingComputing compatibility groups这一步是建立可以批量化计算的节点组。具体做法是，给每一个计算节点建立 signature，用于描述节点计算的特性，文中举出了如下几个例子: Component-wise operations: 直接施加在每个张量元素上的计算，跟张量的维度无关，如$tanh$,$log$ Dimension-sensitive operations: 基于维度的计算，如线性传递$Wh+b$，要求$W$和$h$维度相符，signature 中要包含维度信息 Operations with shared elements: 包含共享元素的计算，如共享的权值$W$ Unbatchable operations: 其他 Determining execution order执行顺序要满足两个目标： 每一节点的计算要在其依赖之后 带有同样 signature 且没有依赖关系的节点放在同一批量执行 但在一般情况下找到最大化批量规模的执行顺序是个NP问题。有如下两种策略： Depth-based Batching: 库Tensorflow Fold中使用的方法。某一节点的深度定义为其子节点到其本身的最大长度，同一深度的节点进行批量计算。但由于输入序列长度不一，可能会错失一些批量化的机会。 Agenda-based Batching: 本文的方法，核心的想法是维护一个 agenda 序列，所有依赖已经被解析的节点入列，每次迭代时从 agenda 序列中按 signature 相同的原则取出节点进行批量计算。 实验文章选取了四个模型：BiLSTM, BiLSTM w/char, Tree-structured LSTMs, Transition-based Dependency Parsing。 实验结果：（单位为Sentences/second） 小结本来读到题目还是蛮惊喜的，期待的是从模型构建的角度解决序列长度不一带来的计算上的不便。但通读下来发现是在计算图的计算这一层面进行的优化，有些失望但也感激，作者使用DyNet框架实现了他们的方法，希望自己也可以为Pytorch等框架该算法的实现出一份力。 感谢这些开源的框架，正一步步拉近人类构建模型和机器高效计算之间的距离。","categories":[{"name":"Papers","slug":"Papers","permalink":"http://blog.ddlee.cn/categories/Papers/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://blog.ddlee.cn/tags/AI/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://blog.ddlee.cn/tags/Deep-Learning/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://blog.ddlee.cn/tags/Machine-Learning/"},{"name":"Paper","slug":"Paper","permalink":"http://blog.ddlee.cn/tags/Paper/"}]},{"title":"LSTM:Pytorch实现","slug":"LSTM-Pytorch实现","date":"2017-05-28T17:06:44.000Z","updated":"2017-05-28T17:16:51.094Z","comments":true,"path":"2017/05/29/LSTM-Pytorch实现/","link":"","permalink":"http://blog.ddlee.cn/2017/05/29/LSTM-Pytorch实现/","excerpt":"","text":"本文讨论LSTM网络的Pytorch实现，兼论Pytorch库的代码组织方式和架构设计。 LSTMLSTM是一种循环神经网络，适用于对序列化的输入建模。Chris Olah的这篇文章细致地解释了一个LSTM单元的运作方式，建议阅读。 两个想法Gate：信息流动的闸门i_t = sigmoid(W_{xi} x_t + W_{hi}h_{t-1} + b_i)f_t = sigmoid(W_{xf} x_t + W_{hf}h_{t-1} + b_f)o_t = sigmoid(W_{xo} x_t + W_{ho}h_{t-1} + b_o)$x$ 表示输入，$h$表示隐藏状态，用$sigmoid$函数将输入二者的传递结果映射到$（0,1)$上，分别赋予输入门、遗忘门、输出门的含义，来控制不同神经单元（同一神经元不同时间点的状态）之间信息流动。 Cell：记忆池c_t = f_t \\odot c_{t - 1} + i_t \\odot tanh(W_{xc} x_t + W_{hc}h_{t-1} + b_c)\\\\ h_t = o_t \\odot tanh(c_t)$h$表示隐藏状态，$C$表示记忆池，通过Gate，上一单元（状态）的信息有控制地遗忘，当前的输入有控制地流入，记忆池中的信息有控制地流入隐藏状态。 与普通RNN的对比普通RNN只有一个自更新的隐藏状态单元。 LSTM增加了记忆池Cell，并通过几个Gate将信息有控制地更新在记忆池中，并通过记忆池中的信息来决定隐藏状态。 From Scratch下面是手动实现LSTM的代码，继承了基类nn.Module。 import torch.nn as nn import torch from torch.autograd import Variable class LSTM(nn.Module): def __init__(self, input_size, hidden_size, cell_size, output_size): super(LSTM, self).__init__() self.hidden_size = hidden_size self.cell_size = cell_size self.gate = nn.Linear(input_size + hidden_size, cell_size) self.output = nn.Linear(hidden_size, output_size) self.sigmoid = nn.Sigmoid() self.tanh = nn.Tanh() self.softmax = nn.LogSoftmax() def forward(self, input, hidden, cell): combined = torch.cat((input, hidden), 1) f_gate = self.gate(combined) i_gate = self.gate(combined) o_gate = self.gate(combined) f_gate = self.sigmoid(f_gate) i_gate = self.sigmoid(i_gate) o_gate = self.sigmoid(o_gate) cell_helper = self.gate(combined) cell_helper = self.tanh(cell_helper) cell = torch.add(torch.mul(cell, f_gate), torch.mul(cell_helper, i_gate)) hidden = torch.mul(self.tanh(cell), o_gate) output = self.output(hidden) output = self.softmax(output) return output, hidden, cell def initHidden(self): return Variable(torch.zeros(1, self.hidden_size)) def initCell(self): return Variable(torch.zeros(1, self.cell_size)) 几个关键点： Tensor的大小 信息的传递顺序 Pytorch ModulePytorch库本身对LSTM的实现封装了更多功能，类和函数的组织也非常有借鉴意义。我对其实现的理解基于以下两点展开： 胞(cell)、层(layer)、栈(stacked layer)的层次化解耦，每一层抽象处理一部分参数（结构） 函数句柄的传递：处理好参数后返回函数句柄forward 下面开始按图索骥，源码见GitHub。 LSTM类文件：nn/modules/rnn.py # nn/modules/rnn.py class RNNBase(Module): def __init__(self, mode, input_size, output_size): pass def forward(self, input, hx=None): if hx is None: hx = torch.autograd.Variable() if self.mode == 'LSTM': hx = (hx, hx) func = self._backend.RNN() #!!! output, hidden = func(input, self.all_weights, hx) #!!! return output, hidden class LSTM(RNNBase): def __init__(self, *args, **kwargs): super(LSTM, self).__init__('LSTM', *args, **kwargs) LSTM类只是RNNBase类的一个装饰器。 在基类nn.Module中，把__call__()定义为调用forward()方法，因而真正的功能实现在_backend.RNN()中 AutogradRNN函数下面寻找_backend.RNN。文件：nn/backends/thnn.py # nn/backends/thnn.py def _initialize_backend(): from .._functions.rnn import RNN, LSTMCell 原来，_backend也是索引。 终于找到RNN()函数。文件：nn/_functions/rnn.py # nn/_functions/rnn.py def RNN(*args, **kwargs): def forward(input, *fargs, **fkwargs): func = AutogradRNN(*args, **kwargs) return func(input, *fargs, **fkwargs) return forward def AutogradRNN(mode, input_size, hidden_size): cell = LSTMCell rec_factory = Recurrent layer = (rec_factory(cell),) func = StackedRNN(layer, num_layers) def forward(input, weight, hidden): nexth, output = func(input, hidden, weight) return output, nexth return forward RNN()是一个装饰器，根据是否有cudnn库决定调用AutogradRNN()还是CudnnRNN()，这里仅观察AutogradRNN() AutogradRNN()选用了LSTMCell，用Recurrent()函数处理了Cell构成Layer，再将Layer传入StackedRNN()函数 RNN()和AutogradRNN()返回的都是其forward()函数句柄 下面是Recurrent()函数： def Recurrent(inner): def forward(input, hidden, weight): output = [] steps = range(input.size(0) - 1, -1, -1) for i in steps: hidden = inner(input[i], hidden, *weight) output.append(hidden[0]) return hidden, output return forward Recurrent()函数实现了“递归”的结构，根据输入的大小组合Cell，完成了隐藏状态和参数的迭代。 Recurrent()函数将Cell(inner)组合为Layer。 StackedRNN()函数def StackedRNN(inners, num_layers): num_directions = len(inners) total_layers = num_layers * num_directions def forward(input, hidden, weight): next_hidden = [] hidden = list(zip(*hidden)) for i in range(num_layers): all_output = [] for j, inner in enumerate(inners): hy, output = inner(input, hidden[l], weight[l]) next_hidden.append(hy) all_output.append(output) input = torch.cat(all_output, input.dim() - 1) next_h, next_c = zip(*next_hidden) next_hidden = (torch.cat(next_h, 0).view(total_layers, *next_h[0].size()), torch.cat(next_c, 0).view(total_layers, *next_c[0].size())) return next_hidden, input return forward StackedRNN()函数将Layer(inner)组合为栈 最后的最后，一个基本的LSTM单元内的计算由LSTMCell()函数实现。 LSTMCell()函数def LSTMCell(input, hidden, w_ih, w_hh, b_ih=None, b_hh=None): if input.is_cuda: igates = F.linear(input, w_ih) hgates = F.linear(hidden[0], w_hh) state = fusedBackend.LSTMFused() return state(igates, hgates, hidden[1]) if b_ih is None else state(igates, hgates, hidden[1], b_ih, b_hh) hx, cx = hidden gates = F.linear(input, w_ih, b_ih) + F.linear(hx, w_hh, b_hh) ingate, forgetgate, cellgate, outgate = gates.chunk(4, 1) ingate = F.sigmoid(ingate) forgetgate = F.sigmoid(forgetgate) cellgate = F.tanh(cellgate) outgate = F.sigmoid(outgate) cy = (forgetgate * cx) + (ingate * cellgate) hy = outgate * F.tanh(cy) return hy, cy 观察上面的代码，即是LSTM的基本信息传递公式。至此，我们的旅程完成。 小结 没有什么是增加一层抽象不能解决的，如果不能，那就再加一层。 重复一下我对上述代码的理解： 胞(cell)、层(layer)、栈(stacked layer)的层次化解耦，每一层抽象处理一部分参数（结构） 函数句柄的传递：处理好参数后返回函数句柄forward 如洋葱一般，我们剥到最后，发现处理的信息正是输入、隐藏状态和LSTM单元几个控制门的参数。在一层一层的抽象之中，Pytorch在不同的层面处理了不同的参数，保证了扩展性和抽象层之间的解耦。","categories":[{"name":"AI","slug":"AI","permalink":"http://blog.ddlee.cn/categories/AI/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://blog.ddlee.cn/tags/AI/"},{"name":"Python","slug":"Python","permalink":"http://blog.ddlee.cn/tags/Python/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://blog.ddlee.cn/tags/Deep-Learning/"},{"name":"Pytorch","slug":"Pytorch","permalink":"http://blog.ddlee.cn/tags/Pytorch/"}]},{"title":"Pandas速度优化","slug":"Pandas速度优化","date":"2017-05-28T12:06:14.000Z","updated":"2017-05-28T12:17:21.127Z","comments":true,"path":"2017/05/28/Pandas速度优化/","link":"","permalink":"http://blog.ddlee.cn/2017/05/28/Pandas速度优化/","excerpt":"","text":"本文主要内容取自Sofia Heisler在PyCon 2017上的演讲No More Sad Pandas Optimizing Pandas Code for Speed and Efficiency，讲稿代码和幻灯片见GitHub。 Set Up示例数据 ean_hotel_id name address1 city state_province postal_code latitude longitude star_rating high_rate low_rate 0 269955 Hilton Garden Inn Albany/SUNY Area 1389 Washington Ave Albany NY 12206 42.68751 -73.81643 3.0 154.0272 124.0216 1 113431 Courtyard by Marriott Albany Thruway 1455 Washington Avenue Albany NY 12206 42.68971 -73.82021 3.0 179.0100 134.0000 2 108151 Radisson Hotel Albany 205 Wolf Rd Albany NY 12205 42.72410 -73.79822 3.0 134.1700 84.1600 示例函数：Haversine Distancedef haversine(lat1, lon1, lat2, lon2): miles_constant = 3959 lat1, lon1, lat2, lon2 = map(np.deg2rad, [lat1, lon1, lat2, lon2]) dlat = lat2 - lat1 dlon = lon2 - lon1 a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2 c = 2 * np.arcsin(np.sqrt(a)) mi = miles_constant * c return mi 优化它之前，先测量它IPython Notebook的Magic Command: %timeit既可以测量某一行代码的执行时间，又可以测量整个单元格里代码快的执行时间。 Package: line_profiler记录每行代码的执行次数和执行时间。 在IPython Notebook中使用时，先运行%load_ext line_profiler， 之后可以用%lprun -f [function name]命令记录指定函数的执行情况。 实验对行做循环(Baseline)%%timeit haversine_series = [] for index, row in df.iterrows(): haversine_series.append(haversine(40.671, -73.985,\\ row['latitude'], row['longitude'])) df['distance'] = haversine_series Output: 197 ms ± 6.65 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) pd.DataFrame.apply()方法%lprun -f haversine \\ df.apply(lambda row: haversine(40.671, -73.985,\\ row['latitude'], row['longitude']), axis=1) Output: 90.6 ms ± 7.55 ms per loop (mean ± std. dev. of 7 runs, 10 loops each) Timer unit: 1e-06 s Total time: 0.049982 s File: &lt;ipython-input-3-19c704a927b7&gt; Function: haversine at line 1 Line # Hits Time Per Hit % Time Line Contents ============================================================== 1 def haversine(lat1, lon1, lat2, lon2): 2 1631 1535 0.9 3.1 miles_constant = 3959 3 1631 16602 10.2 33.2 lat1, lon1, lat2, lon2 = map(np.deg2rad, [lat1, lon1, lat2, lon2]) 4 1631 2019 1.2 4.0 dlat = lat2 - lat1 5 1631 1143 0.7 2.3 dlon = lon2 - lon1 6 1631 18128 11.1 36.3 a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2 7 1631 7857 4.8 15.7 c = 2 * np.arcsin(np.sqrt(a)) 8 1631 1708 1.0 3.4 mi = miles_constant * c 9 1631 990 0.6 2.0 return mi 观察Hits这一列可以看到，apply()方法还是将函数一行行地应用于每行。 向量化：将pd.Series传入函数%lprun -f haversine haversine(40.671, -73.985,\\ df[&#39;latitude&#39;], df[&#39;longitude&#39;]) Output: 2.21 ms ± 230 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) Timer unit: 1e-06 s Total time: 0.008601 s File: &lt;ipython-input-3-19c704a927b7&gt; Function: haversine at line 1 Line # Hits Time Per Hit % Time Line Contents ============================================================== 1 def haversine(lat1, lon1, lat2, lon2): 2 1 3 3.0 0.0 miles_constant = 3959 3 1 838 838.0 9.7 lat1, lon1, lat2, lon2 = map(np.deg2rad, [lat1, lon1, lat2, lon2]) 4 1 597 597.0 6.9 dlat = lat2 - lat1 5 1 572 572.0 6.7 dlon = lon2 - lon1 6 1 5033 5033.0 58.5 a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2 7 1 1060 1060.0 12.3 c = 2 * np.arcsin(np.sqrt(a)) 8 1 496 496.0 5.8 mi = miles_constant * c 9 1 2 2.0 0.0 return mi 向量化之后，函数内的每行操作只被访问一次，达到了行结构上的并行。 向量化：将np.array传入函数%lprun -f haversine df['distance'] = haversine(40.671, -73.985,\\ df['latitude'].values, df['longitude'].values) Output： 370 µs ± 18 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each) Timer unit: 1e-06 s Total time: 0.001382 s File: &lt;ipython-input-3-19c704a927b7&gt; Function: haversine at line 1 Line # Hits Time Per Hit % Time Line Contents ============================================================== 1 def haversine(lat1, lon1, lat2, lon2): 2 1 3 3.0 0.2 miles_constant = 3959 3 1 292 292.0 21.1 lat1, lon1, lat2, lon2 = map(np.deg2rad, [lat1, lon1, lat2, lon2]) 4 1 40 40.0 2.9 dlat = lat2 - lat1 5 1 29 29.0 2.1 dlon = lon2 - lon1 6 1 815 815.0 59.0 a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2 7 1 183 183.0 13.2 c = 2 * np.arcsin(np.sqrt(a)) 8 1 18 18.0 1.3 mi = miles_constant * c 9 1 2 2.0 0.1 return mi 相比pd.Series，np.array不含索引等额外信息，因而更加高效。 小结 Methodology Avg. single run time Marginal performance improvement Looping with iterrows 184.00 - Looping with apply 78.10 2.4x Vectorization with Pandas series 1.79 43.6x Vectorization with NumPy arrays 0.37 4.8x 通过上面的对比，我们比最初的baseline快了近500倍。最大的提升来自于向量化。因而，实现的函数能够很方便地向量化是高效处理的关键。 用Cython优化Cython可以将python代码转化为C代码来执行，可以进行如下优化（静态化变量类型，调用C函数库） %load_ext cython %%cython -a # Haversine cythonized from libc.math cimport sin, cos, acos, asin, sqrt cdef deg2rad_cy(float deg): cdef float rad rad = 0.01745329252*deg return rad cpdef haversine_cy_dtyped(float lat1, float lon1, float lat2, float lon2): cdef: float dlon float dlat float a float c float mi lat1, lon1, lat2, lon2 = map(deg2rad_cy, [lat1, lon1, lat2, lon2]) dlat = lat2 - lat1 dlon = lon2 - lon1 a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2 c = 2 * asin(sqrt(a)) mi = 3959 * c return mi 嵌套于循坏中： %timeit df['distance'] =\\ df.apply(lambda row: haversine_cy_dtyped(40.671, -73.985,\\ row['latitude'], row['longitude']), axis=1) Output: 10 loops, best of 3: 68.4 ms per loop 可以看到，Cython确实带来速度上的提升，但效果不及向量化（并行化）。","categories":[{"name":"Data Science","slug":"Data-Science","permalink":"http://blog.ddlee.cn/categories/Data-Science/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://blog.ddlee.cn/tags/Python/"},{"name":"Data Science","slug":"Data-Science","permalink":"http://blog.ddlee.cn/tags/Data-Science/"},{"name":"Programming","slug":"Programming","permalink":"http://blog.ddlee.cn/tags/Programming/"}]},{"title":"Python可视化工具指引","slug":"Python可视化工具指引","date":"2017-05-27T16:12:28.000Z","updated":"2017-06-03T04:27:24.027Z","comments":true,"path":"2017/05/28/Python可视化工具指引/","link":"","permalink":"http://blog.ddlee.cn/2017/05/28/Python可视化工具指引/","excerpt":"","text":"本文主要材料来自Jake VanderPlas在PyCon 2017上的演讲Python’s Visualization Landscape Python真是越来越火了。活跃的开源社区为Python这门语言贡献着长青的活力。 子曾经曰过：轮子多了，车就稳了。 本文帮助你选好轮子，也祝愿可视化的车开得越来越稳。 The Landscape 如图。 VanderPlas在展示完这张全景图后给大家贴了这张图： 我差点笑喷。我们的表情包可能要在人民币之前走向国际化了。 回到正题，可视化工具有两个主要阵营，一是基于matplotlib，二是基于JavaScript。还有的接入了JS下著名的D3.js库。 Matplotlibnumpy, pandas, matplotlib可以说是python数据科学的三驾马车。凡以python为教学语言的数据科学相关课程必提这三个库。而matplotlib又有什么特点呢？ 先说优点： 像MATLAB的语法，对MATLAB用户好上手 稳定，久经考验 渲染后端丰富，跨平台（GTK, Qt5, svg, pdf等） 缺点也有很多： API过于繁琐 默认配色太丑 对web支持差，交互性差 对大数据集处理较慢 于是就有了很多基于matplotlib的扩展，提供了更丰富、更人性化的API。 下面是几个比较受欢迎的包： pandaspandas的DataFrame对象是有plot()方法的，如：iris.plot.scatter(&#39;petalLength&#39;, &#39;petalWidth&#39;)生成二维散点图，只需指明两个轴取自哪一列数据即可。 seabornseaborn(gallery)专注于统计数据可视化，默认配色也还可以。语法示例： import seaborn as sns sns.lmplot('petalLength', 'sepalWidth', iris, hue='species', fit_reg=False) 类ggplot对于R用户，最熟悉的可视化包可能是ggplot2，在python中可以考虑ggpy(https://github.com/yhat/ggpy)和近期上了Github Trends的plotnie(https://github.com/has2k1/plotnine)。 JavaScript基于JS的包常常具有非常好的交互性，其共同点是将图形格式化为json文件，再由JS完成渲染。 BokehBokeh(Gallery)定位于绘制用于浏览器展示的交互式图形。其优点是交互性、能够处理大量数据和流数据。语法示例： p = figure() p.circle(iris.petalLength, iris.sepalWidth) show(p) PlotlyPlotly(Gallery)跟Bokeh类似。但其提供了多种语言接口(JS, R, Python, MATLAB)，并且支持3D和动画效果，缺点是有些功能需要付费。语法示例： from plotly.graph_objs import Scatter from plotly.offline import iplot p = Scatter(x=iris.petalLength, y=iris.sepalWidth, mode='markers') iplot(p) 处理大型数据集对于大型数据集，可以考虑的包包括datashader, Vaex, 基于OpenGL的Vispy和Glumpy，GlueViz等。这里介绍datashader。 datashaderdatashader是Bokeh的子项目，为处理大型数据集而生。 示例语法： from colorcet import fire export(tf.shade(agg, cmap=cm(fire, 0.2), how='eq_hist'), 'census_ds_fier_eq_hist') 最终的建议上车忠告： matplotlib必会 R用户：ggpy/plotnine 交互式：plotly(与R接口统一)/bokeh(免费)","categories":[{"name":"Data Science","slug":"Data-Science","permalink":"http://blog.ddlee.cn/categories/Data-Science/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://blog.ddlee.cn/tags/Python/"},{"name":"Visualization","slug":"Visualization","permalink":"http://blog.ddlee.cn/tags/Visualization/"}]},{"title":"[论文笔记]Deep Learning","slug":"论文笔记-Deep-Learning","date":"2017-05-23T11:09:09.000Z","updated":"2017-06-02T11:24:55.784Z","comments":true,"path":"2017/05/23/论文笔记-Deep-Learning/","link":"","permalink":"http://blog.ddlee.cn/2017/05/23/论文笔记-Deep-Learning/","excerpt":"","text":"论文：Deep Learning 这篇文章是三位大牛15年发表在Nature上有关深度学习的综述，尽管这两年深度学习又有更多的模型和成果出现，文章显得有些过时，但来自三位领军人物对深度学习的深度阐述还是值得反复回味。 Abstract摘要的第一句话可以说给深度学习下了定义。有一些观点认为深度学习就是堆叠了很多层的神经网络，因计算力的提升而迎来第二春。但请看三位是怎么说的： Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. 也就是说，深度学习是允许由 多个处理层构成的计算模型 用多个层次的 抽象 来习得 数据表示 的技术。我的解读如下： 深度学习不限于神经网络模型，其关键之处在于多层的表示 深度学习属于表示学习，目的是习得数据的某种表示，而这种表示由多个层次的抽象完成 在第一段的导言中，文章总结了深度学习技术取得突破性成果的各个领域，也再次指出了深度学习与传统学习算法的不同之处： 传统学习模型需要特征工程和领域知识来从数据构建较好的特征 深度学习中，多层的特征由通用的学习过程得到，而不需要人类工程师的参与 Supervised learning这一段概述了监督学习的一般框架、优化策略，并指出浅层学习需要Feature Extractor来提取对最适合目标问题的特征。 Backpropagation to train multilayer architectures这一段指出BP算法的关键在于目标函数关于某一子模块输入的导数可以反向通过目标函数关于该子模块输出的导数得出，而这一过程是可迭代的。BP算法曾因容易陷于局部最优解而被冷落，但对于大型网络，在实践中，理论和经验都表明尽管落于局部最优解，但这个解的效果却和全局最优解相差无几，而且几乎所有的局部最优解都可以取得类似的效果。 Convolutional neural networks巻积网络背后有四个关键想法： local connections shared weights pooling the use of many layers 巻积网络常由巻积层、池化层和激活层构成，巻积层用于提取局部特征，池化层用于整合相似的特征，激活层用于加入非线性。这样的结构有两点理由： 张量性数据的局部数值常常高度相关，局部特征容易发现 局部特征跟位置无关（平移不变性） 文章也提到了这种巻积结构的仿生学证据。 Image understanding with deep convolutional networks这一段总结了巻积网路在图像方面取得的成就。 Distributed representations and language processing分布式表示在两点上可以取得指数级增益： 习得特征的不同组合可以泛化出训练数据中不存在的类型 特征组合的个数的增加关于层数是指数级的 文章还比较了分布式表示相比传统的词频统计在表述人类语言方面的优势。 Recurrent neural networks这一段概述了循环神经网络的动态特性和LSTM等结构上的改进。 The future of deep learning作者认为在长期看来，无监督学习会更为重要，人工智能领域的重大飞跃将由组合了表示学习和复杂推理的系统取得。","categories":[{"name":"Papers","slug":"Papers","permalink":"http://blog.ddlee.cn/categories/Papers/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://blog.ddlee.cn/tags/AI/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://blog.ddlee.cn/tags/Deep-Learning/"},{"name":"Papers","slug":"Papers","permalink":"http://blog.ddlee.cn/tags/Papers/"}]},{"title":"Dropout-Pytorch实现","slug":"Dropout-Pytorch实现","date":"2017-05-17T11:30:44.000Z","updated":"2017-06-03T08:32:34.577Z","comments":true,"path":"2017/05/17/Dropout-Pytorch实现/","link":"","permalink":"http://blog.ddlee.cn/2017/05/17/Dropout-Pytorch实现/","excerpt":"","text":"Dropout技术是Srivastava等人在2012年提出的技术，现在已然成为各种深度模型的标配。其中心思想是随机地冻结一部分模型参数，用于提高模型的泛化性能。 Dropout的洞察关于Dropout，一个流行的解释是，通过随机行为训练网络，并平均多个随机决定的结果，实现了参数共享的Bagging。如下图，通过随机地冻结/抛弃某些隐藏单元，我们得到了新的子网络，而参数共享是说，与Bagging中子模型相互独立的参数不同，深度网络中Dropout生成的子网络是串行的，后一个子模型继承了前一个子模型的某些参数。 Dropout是模型自我破坏的一种形式，这种破坏使得存活下来的部分更加鲁棒。例如，某一隐藏单元学得了脸部鼻子的特征，而在Dropout中遭到破坏，则在之后的迭代中，要么该隐藏单元重新学习到鼻子的特征，要么学到别的特征，后者则说明，鼻子特征对该任务来说是冗余的，因而，通过Dropout，保留下来的特征更加稳定和富有信息。 Hinton曾用生物学的观点解释这一点。神经网络的训练过程可以看做是生物种群逐渐适应环境的过程，在迭代中传递的模型参数可以看做种群的基因，Dropout以随机信号的方式给环境随机的干扰，使得传递的基因不得不适应更多的情况才能存活。 另一个需要指出的地方是，Dropout给隐藏单元加入的噪声是乘性的，不像Bias那样加在隐藏单元上，这样在进行反向传播时，Dropout引入的噪声仍能够起作用。 代码实现下面看在实践中，Dropout层是如何实现的。简单来说，就是生成一系列随机数作为mask，然后再用mask点乘原有的输入，达到引入噪声的效果。 From Scratch# forward pass def dropout_forward(x, dropout_param): p, mode = dropout_param['p'], dropout_param['mode'] # p: dropout rate; mode: train or test if 'seed' in dropout_param: np.random_seed(dropout_param['seed']) # seed: random seed mask = None out = None if mode == 'train': mask = (np.random.rand(*x.shape) >= p)/(1-p) # 1-p as normalization multiplier: to keep the size of input out = x * mask elif mode == 'test': # do nothing when perform inference out = x cache = (dropout_param, mask) out = out.astype(x.dtype, copy=False) return out, cache # backward pass def dropout_backward(dout, cache): dropout_param, mask = cache mode = dropout_param['mode'] dx = None if mode == 'train': dx = dout * mask elif mode == 'test': dx = dout return dx Pytorch实现file: /torch/nn/_functions/dropout.py class Dropout(InplaceFunction): def __init__(self, p=0.5, train=False, inplace=False): super(Dropout, self).__init__() if p < 0 or p > 1: raise ValueError(\"dropout probability has to be between 0 and 1, \" \"but got {}\".format(p)) self.p = p self.train = train self.inplace = inplace def _make_noise(self, input): # generate random signal return input.new().resize_as_(input) def forward(self, input): if self.inplace: self.mark_dirty(input) output = input else: output = input.clone() if self.p > 0 and self.train: self.noise = self._make_noise(input) # multiply mask to input self.noise.bernoulli_(1 - self.p).div_(1 - self.p) if self.p == 1: self.noise.fill_(0) self.noise = self.noise.expand_as(input) output.mul_(self.noise) return output def backward(self, grad_output): if self.p > 0 and self.train: return grad_output.mul(self.noise) else: return grad_output","categories":[{"name":"AI","slug":"AI","permalink":"http://blog.ddlee.cn/categories/AI/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://blog.ddlee.cn/tags/AI/"},{"name":"Python","slug":"Python","permalink":"http://blog.ddlee.cn/tags/Python/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://blog.ddlee.cn/tags/Deep-Learning/"},{"name":"Pytorch","slug":"Pytorch","permalink":"http://blog.ddlee.cn/tags/Pytorch/"}]},{"title":"[论文笔记]Visualizing and Understanding Recurrent Networks","slug":"论文笔记-Visualizing-and-Understanding-Recurrent-Networks","date":"2017-05-13T06:06:51.000Z","updated":"2017-06-03T04:35:09.919Z","comments":true,"path":"2017/05/13/论文笔记-Visualizing-and-Understanding-Recurrent-Networks/","link":"","permalink":"http://blog.ddlee.cn/2017/05/13/论文笔记-Visualizing-and-Understanding-Recurrent-Networks/","excerpt":"","text":"论文： Visualizing and Understanding Recurrent Networks 实验设定字母级的循环神经网络，用Torch实现，代码见GitHub。字母嵌入成One-hot向量。优化方面，采用了RMSProp算法，加入了学习速率的decay和early stopping。 数据集采用了托尔斯泰的《战争与和平》和Linux核心的代码。 可解释性激活的例子$tanh$函数激活的例子，$-1$为红色，$+1$为蓝色。 上图分别是记录了行位置、引文和if语句特征的例子和失败的例子。 上图分别是记录代码中注释、代码嵌套深度和行末标记特征的例子。 Gates数值的统计 此图信息量很大。 left-saturated和right-saturated表示各个Gates激活函数（$sigmoid$）小于0.1和大于0.9，即总是阻止信息流过和总是允许信息流过。 横轴和纵轴表示该Gate处于这两种状态的时间比例，即有多少时间是阻塞状态，有多少时间是畅通状态。 三种颜色表示不同的层。 有以下几个观察： 第一层的门总是比较中庸，既不阻塞，也不畅通 第二三层的门在这两种状态间比较分散，经常处于畅通状态的门可能记录了长期的依赖信息，而经常处于阻塞状态的门则负责了短期信息的控制。 错误来源分析在这一节，作者用了“剥洋葱”的方法，建立了不同的模型将错误进行分解。此处错误指LSTM预测下一个字母产生的错误，数据集为托尔斯泰的《战争与和平》。 n-gram Dynamic n-long memory，即对已经出现过得单词的复现。如句子”Jon yelled atMary but Mary couldn’t hear him.”中的Mary。 Rare words，不常见单词 Word model，单词首字母、新行、空格之后出现的错误 Punctuation，标点之后 Boost，其他错误 根据作者的实验，错误的来源有如下分解： 小结这篇文章是打开LSTM黑箱的尝试，提供了序列维度上共享权值的合理性证据，对Gates状态的可视化也非常值得关注，最后对误差的分解可能对新的网络结构有所启发（比如，如何将单词级别和字母级别的LSTM嵌套起来，解决首字母预测的问题？）。","categories":[{"name":"Papers","slug":"Papers","permalink":"http://blog.ddlee.cn/categories/Papers/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://blog.ddlee.cn/tags/AI/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://blog.ddlee.cn/tags/Deep-Learning/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://blog.ddlee.cn/tags/Machine-Learning/"},{"name":"Papers","slug":"Papers","permalink":"http://blog.ddlee.cn/tags/Papers/"}]},{"title":"[论文笔记]Deep Residual Learning for Image Recognition","slug":"论文笔记-Deep-Residual-Learning-for-Image-Recognition","date":"2017-04-30T15:12:11.000Z","updated":"2017-05-30T13:37:55.644Z","comments":true,"path":"2017/04/30/论文笔记-Deep-Residual-Learning-for-Image-Recognition/","link":"","permalink":"http://blog.ddlee.cn/2017/04/30/论文笔记-Deep-Residual-Learning-for-Image-Recognition/","excerpt":"","text":"论文：Deep Residual Learning for Image Recognition 背景网络在堆叠到越来越深之后，由于BP算法所依赖的链式法则的连乘形式，会出现梯度消失和梯度下降的问题。初始标准化和中间标准化参数在一定程度上缓解了这一问题，但仍然存在更深的网络比浅层网络具有更大的训练误差的问题。 基本结构假设多层的网络结构能够任意接近地拟合目标映射$H(x)$，那么也能任意接近地拟合其关于恒等映射的残差函数$H(x)-x$。记$F(x)=H(x)-x$，则原来的目标映射表为$F(x)+x$。由此，可以设计如下结构。 残差单元 残差单元包含一条恒等映射的捷径，不会给原有的网络结构增添新的参数。 动机/启发层数的加深会导致更大的训练误差，但只增加恒等映射层则一定不会使训练误差增加，而若多层网络块要拟合的映射与恒等映射十分类似时，加入的捷径便可方便的发挥作用。 实验文章中列举了大量在ImagNet和CIFAR-10上的分类表现，效果很好，在此不表。 拾遗Deeper Bottleneck Architectures 两头的1 * 1巻积核先降维再升维，中间的3 * 3巻积核成为“瓶颈”，用于提取重要的特征。这样的结构跟恒等映射捷径配合，在ImageNet上有很好的分类效果。 Standard deviations of layer responses上图是在CIFAR-10数据集上训练的网络各层的相应方差（Batch-Normalization之后，激活之前）。可以看到，残差网络相对普通网络有更小的方差。这一结果支持了残差函数比非残差函数更接近于0的想法（即更接近恒等映射）。此外，还显示出网络越深，越倾向于保留流过的信息。 小结深度残差网络在当年的比赛中几乎是满贯。下面是我的一些（未经实验证实的）理解： 首先，其”跳级”的网络结构对深度网络的设计是一种启发，通过“跳级”，可以把之前网络的信息相对完整的跟后层网络结合起来，即低层次解耦得到的特征和高层次解耦得到的特征再组合。再者，这种分叉的结构可以看作网络结构层面的”Dropout”: 如果被跳过的网络块不能习得更有用的信息，就被恒等映射跳过了。","categories":[{"name":"Papers","slug":"Papers","permalink":"http://blog.ddlee.cn/categories/Papers/"}],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://blog.ddlee.cn/tags/Deep-Learning/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://blog.ddlee.cn/tags/Machine-Learning/"},{"name":"Papers","slug":"Papers","permalink":"http://blog.ddlee.cn/tags/Papers/"},{"name":"Computer Vision","slug":"Computer-Vision","permalink":"http://blog.ddlee.cn/tags/Computer-Vision/"}]},{"title":"[论文笔记]Tensorflow White Paper","slug":"Tensorflow-White-Paper","date":"2017-04-20T13:32:29.000Z","updated":"2017-05-30T13:33:20.407Z","comments":true,"path":"2017/04/20/Tensorflow-White-Paper/","link":"","permalink":"http://blog.ddlee.cn/2017/04/20/Tensorflow-White-Paper/","excerpt":"","text":"论文：TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems 抽象Computation Graph整张图如同管道结构，数据流就是其中的水流。Control Dependency 描述了管道的有向结构，而反向传播可以通过增加新的管道节点来实现。 Operation即计算操作的抽象，相当于映射、函数。 Kernel执行计算的单元，CPU或GPU SessionClient-Server结构，进行计算或者调整图结构则视为一次会话 Variables特殊的Operation，返回一个句柄，指向持久化的张量，这些张量在整张图的计算中不会被释放。 Device对Kernel的封装，包含类型属性，实行注册机制维护可供使用的Device列表。 多机实现要考虑两个问题： 计算节点在Device间的分配问题 Devices之间的通信 针对这两个问题，分别建立了两个抽象层。 计算节点分配的C/S机制client提出计算请求，master负责切割计算图为子图，分配子图到Devices。分配时，会模拟执行子图，并采取贪心的策略分配。 不同Device之间的发送和接收节点 在每个Device上建立Receive和Send节点，负责与其他Device通信。 优化数据化并行 上：单线程，同步数据并行下：多线程，异步更新 拾遗文章中很多内容并没涉及到（看不懂）。 小结TensorFlow是个庞大的计算框架，不仅仅定位于深度网络。其对计算图的抽象和数据、计算资源的分配的处理是值得关注的。","categories":[{"name":"Papers","slug":"Papers","permalink":"http://blog.ddlee.cn/categories/Papers/"}],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://blog.ddlee.cn/tags/Deep-Learning/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://blog.ddlee.cn/tags/Machine-Learning/"},{"name":"Papers","slug":"Papers","permalink":"http://blog.ddlee.cn/tags/Papers/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://blog.ddlee.cn/tags/Tensorflow/"}]},{"title":"编程方法论(一):重构","slug":"编程方法论-重构","date":"2017-04-07T18:21:19.000Z","updated":"2017-04-09T16:38:15.126Z","comments":true,"path":"2017/04/08/编程方法论-重构/","link":"","permalink":"http://blog.ddlee.cn/2017/04/08/编程方法论-重构/","excerpt":"","text":"本文内容主要整理自lynda.com课程Programming Foudations: Refactoring Code和Martin Fowler的重构。全部例子来源于refactoring.com。 内容大纲： Introduction 定义重构是在不影响软件功能的情况下，重新组织代码，使之更清晰、更容易理解的过程。 前提：功能不变 行为：改写代码 目的：提高可理解性 大白话讲，重构就是改写，造福以后需要理解这段代码的人们。 重构不是什么给一件事物下定义，有时候从反方面更好讲些。比如你难给正义下一个定义，但很容易举出什么是非正义的例子。 重构不是Debug，代码已经运行良好 重构不是优化 重构不是添加新功能 也就是说，重构对使用代码的人没有任何好处，对使用者来讲，代码是黑箱。重构是准备给要打开黑箱的人，而那个人常常是你自己。 玄学：Code Smells玄学二字是我自己加的。Martin Fowler当然没有这样说。我只是表达一下对无法精确描述的定义的敬意。 我的理解是Code Smells是best practice和code style的总和，直接和根本来源是自己的代码经验。所谓语感、文笔、血淋淋的人生道理。 准备工作：自动化测试重构当然不是breaking the code，写好测试，保证代码仍能正常运行。 重构范例：方法层面首先是一句良言：哪里加了注视，哪里可能就需要重构。 这一点的潜在信念是，好的代码是self-explained的，通过合理的命名、清晰的组织，代码应该像皇帝的新装那样一目了然。 可以用于重构的工具常见的IDE会有重构的功能，如重命名变量。另外，一个严厉的Linter加上像我这样的强迫癌患者会将风格问题扼杀在摇篮之中。 几个例子举例均以Code smell和重构建议两部分构成，较抽象(wo kan bu dong)的给出代码。 Extract MethodCode smell: 太长的方法，带注释的代码块 重构： 提取，新建，用评论命名 Remove tempsCode smell: 冗余的临时变量（本地） 重构： Replace with Query: 把表达式提取为方法（规模较大） Inline temps: 直接用表达式代替这个变量（规模较小） Add tempsCode smell: 同样的变量有多重含义 重构： Split temporary variable: 同一个临时变量在上下文赋予了不同含义（复用），拆 Remove assignment to parameters: 对参数默认值的设定，在函数内新建变量，初始化这个新变量 Remove assignment to parameters的例子： //Before int discount (int inputVal, int quantity, int yearToDate) { if (inputVal > 50) inputVal -= 2; //After Refactoring int discount (int inputVal, int quantity, int yearToDate) { int result = inputVal; if (inputVal > 50) result -= 2; 这一点基于的信念是，参数只能代表被传进来的变量，不应该在本地再赋予别的含义。 重构范例：类与方法 Move MethodCode smell: feature envy（依恋情结） 用中文来说，是指某个方法操作/使用（依恋）某一个类多过自己所处的类，我们用“出轨”这个词来表示这种现象。但这是违反婚姻法的，因而，我们的重构手段就是，把这个方法移动到它依恋的类中，圆满一段木石良缘。* 重构： 圆满木石良缘。 Extract ClassCode smell: 规模太大的类 重构： 把部分移出，自立门户 Inline ClassCode smell: 冗余的类 重构： 像我这中请天假组内运转几乎不受影响的人，应该清除掉（这是瞎话） Condition Focused（条件语句相关）Code smell: 写完判断条件自己都看不懂/看着难受 重构： Decompose conditional: 分解 Consolidate conditional expression: 多项条件指向同一段后续操作，提取这些条件为方法 Consolidate duplicate conditional fragments: 不同条件的后续操作中含有共同的部分，将共有部分提取出来（不管哪个条件总要执行） Replace condition with polymorphism: 针对有判断分支的方法，替换成多态方法 Replace type code with subclass*: 针对有判断分支的类，替换为子类 Consolidate conditional expression的例子： //Before double disabilityAmount() { if (_seniority < 2) return 0; if (_monthsDisabled > 12) return 0; if (_isPartTime) return 0; // compute the disability amount //After Refactoring double disabilityAmount() { if (isNotEligableForDisability()) return 0; // compute the disability amount 重构范例：数据相关 Move fieldcode smell: inverse feature envy（自造） 某一个类使用某一数据比该数据所属的类还多。 重构：送给你了还不行吗！？ Data Clumps（数据团）code smell: 某些数据总是抱团出现 重构： Preserve whole object: 在一个方法中反复提取某个类的一些属性，将整个对象传入 Introducing parameter object: 把这些参数合并为一个类，把新建的类传入 Similifying重构： Renaming: 顾名思义 Add or remove parameters: 顾名思义 Replace parameter with explicit Method: 根据不同参数值新建专属的方法 Parameterize Method: 与上者相反，把不同方法合并，传入参数 Separate queries form modifiers: 将找到数据和更该数据两个操作拆成两个方法 Replace parameter with explicit Method的例子： //Before void setValue (String name, int value) { if (name.equals(\"height\")) { _height = value; return; } if (name.equals(\"width\")) { _width = value; return; } Assert.shouldNeverReachHere(); } //After Refactoring void setHeight(int arg) { _height = arg; } void setWidth (int arg) { _width = arg; } Pulling and pushing(升级与降级) Pull up method and pull up field Push down method and push down field 解决方法、数据归属不合理的问题。 高阶重构（大坑，大坑）Convert procedural design to objects化函数式变成为面向对象，祝好运。 拾遗写代码和改代码是一个不断被自己坑和被别人坑的旅程。且行且珍惜。 Cheers, have a good one. @ddlee","categories":[{"name":"Programming","slug":"Programming","permalink":"http://blog.ddlee.cn/categories/Programming/"}],"tags":[{"name":"Programming","slug":"Programming","permalink":"http://blog.ddlee.cn/tags/Programming/"},{"name":"Refactoring","slug":"Refactoring","permalink":"http://blog.ddlee.cn/tags/Refactoring/"}]},{"title":"ddlee约书计划（第二弹）","slug":"ddlee约书计划（第二弹）","date":"2017-04-04T16:45:28.000Z","updated":"2017-04-07T18:26:39.880Z","comments":true,"path":"2017/04/05/ddlee约书计划（第二弹）/","link":"","permalink":"http://blog.ddlee.cn/2017/04/05/ddlee约书计划（第二弹）/","excerpt":"","text":"缘起读书这种事情，每几个月都会有那么几天。 浑身难受。不干点什么，眼睛闲得团团转，双手也不知道往哪搁。 大概是愧疚吧。要立个FLAG把这压抑着的自卑和热情释放一下。 花大概十分钟的时间，下载/买下十个月都读不完的书。 书单选书原则： 我感兴趣 拒绝大部头 均为论述类，有的聊 我能提供电子版 书单： 《未来简史》尤瓦尔·赫拉利 《知识的边界》戴维·温伯格 《数字化生存》尼葛洛庞帝 《技术的本质》布莱恩•阿瑟 《科技想要什么》凯文·凯利 《枪炮、病菌与钢铁》贾雷德·戴蒙德 《言论的边界》安东尼·刘易斯 《理解媒介》马歇尔·麦克卢汉 《自私的基因》里查德.道金斯 《真实世界的脉络》戴维·多伊奇 豆列在此 剩下一些，我读过，但意犹未尽，也可以聊。 《中国近代史》徐中约 《人类简史》尤瓦尔·赫拉利 《娱乐至死》尼尔·波兹曼 《浅薄：互联网如何毒害了我们的大脑》尼古拉斯·卡尔 操作有条件的，我们用Google Docs共享想法。没条件的，用Evernote。 如果你不习惯写下来，我们可以线下聊（聊到风花雪月人生哲学就不保证了，所以最好还是写下来）。 拾遗 精力有限，同时运行三个线程，多了就溢出了。 其他书也可以推荐，如果长得足够好看的话，我会同意的。 谁也是诸事缠身，有事情不能坚持的，随时退出，我太能理解了；能坚持读完的，我陪你到最后。 这种计划似乎跟熟人约过一次，没成，向我骚扰过的人抱歉。 如果你感兴趣，私信/微信/邮箱联系我。 @ddlee","categories":[{"name":"Reading","slug":"Reading","permalink":"http://blog.ddlee.cn/categories/Reading/"}],"tags":[{"name":"Reading","slug":"Reading","permalink":"http://blog.ddlee.cn/tags/Reading/"}]},{"title":"Coroutine,Generator,Async与Await","slug":"Coroutine-Generator-Async与Await","date":"2017-04-03T14:57:54.000Z","updated":"2017-04-07T18:27:24.796Z","comments":true,"path":"2017/04/03/Coroutine-Generator-Async与Await/","link":"","permalink":"http://blog.ddlee.cn/2017/04/03/Coroutine-Generator-Async与Await/","excerpt":"","text":"GeneratorGenerator能保存自己的状态，进入一种“Paused”状态，再次调用时会继续执行。 Generator的好处之一是节省了存储空间开销，带一些”流处理”的思想。 其实，我们也可以对Generator进行传入数据的操作： def coro(): hello = yield \"Hello\" yield hello c = coro() print(next(c)) print(c.send(\"World\")) Coroutinecoroutine可以认为是generator思想的泛化： generator一个一个地吐出数据（返回值） coroutine一个一个地吃掉数据（传入参数）并返回结果，即可控地执行函数 关键点在于，generator与coroutine都能保存自己的状态，而这种特点正可以用于任务切换。yield可以看做是操作系统在进行进程管理时的traps: 实际上，coroutine可以看做”用户自定义”的进程，状态、启用和暂停都可控，David Beazley就利用这一点用coroutine实现了Python上的操作系统（参见Reference)。 Conroutine与Concurrent ProgrammingConcurrent Programming中有Task的概念，有如下特点： 独立的控制流 内部状态变量 支持计划任务（暂停、恢复执行） 与其他Task通信 @coroutine def grep(pattern): #正则匹配 print \"Looking for %s\" % pattern while True: line = (yield) if pattern in line: print line, conroutine有自己的控制流（while/if），有局部变量（pattern, line），能暂停和恢复（yield()/send()），能相互通信（send()） ====》coroutine就是一种Task！ Python Docs中提供了一个例子： import asyncio async def compute(x, y): print(\"Compute %s + %s ...\" % (x, y)) await asyncio.sleep(1.0) return x + y async def print_sum(x, y): result = await compute(x, y) print(\"%s + %s = %s\" % (x, y, result)) loop = asyncio.get_event_loop() loop.run_until_complete(print_sum(1, 2)) loop.close() 执行方式如下图： 利用coroutine，可以在一个线程(Task)上实现异步。 Impletationcoroutine有两种实现方式，基于generator和原生async, awati关键字。 generator based coroutineimport asyncio import datetime import random @asyncio.coroutine def display_date(num, loop): end_time = loop.time() + 50.0 while True: print(\"Loop: {} Time: {}\".format(num, datetime.datetime.now())) if (loop.time() + 1.0) >= end_time: break yield from asyncio.sleep(random.randint(0, 5)) loop = asyncio.get_event_loop() asyncio.ensure_future(display_date(1, loop)) asyncio.ensure_future(display_date(2, loop)) loop.run_forever() 上面的程序实现了在同一个线程里交互执行两个函数（sleep），而又能保持各自的状态 Native support(python 3.5+)只需要修改函数定义头和yield from为关键字await即可。 async def display_date(num, loop, ): end_time = loop.time() + 50.0 while True: print(\"Loop: {} Time: {}\".format(num, datetime.datetime.now())) if (loop.time() + 1.0) >= end_time: break await asyncio.sleep(random.randint(0, 5)) 拾遗Coroutine常翻译成“协程”。 Reference: David Beazley @ PyCon2009 Slides PYTHON: GENERATORS, COROUTINES, NATIVE COROUTINES AND ASYNC/AWAIT Python 3.6 Docs: Taks and coroutines @ddlee","categories":[{"name":"Programming","slug":"Programming","permalink":"http://blog.ddlee.cn/categories/Programming/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://blog.ddlee.cn/tags/Python/"},{"name":"异步","slug":"异步","permalink":"http://blog.ddlee.cn/tags/异步/"}]},{"title":"500lines项目Crawler源码阅读笔记","slug":"500lines项目Crawler阅读笔记","date":"2017-04-03T14:57:20.000Z","updated":"2017-04-07T18:27:34.968Z","comments":true,"path":"2017/04/03/500lines项目Crawler阅读笔记/","link":"","permalink":"http://blog.ddlee.cn/2017/04/03/500lines项目Crawler阅读笔记/","excerpt":"","text":"源码来自GitHub上著名的Repo: 500lines or less。 整体结构 代码结构由crawling, crawl, reporting三大部分组成。 crawl: 驱动，解析传入的参数，管理loop，调用crawler，生成report Crawling: 实现crawler类及一系列辅助函数 reporting： 生成记录 Crawler类Crawler类实现了解析网址，抓取内容等基本功能，利用asyncio库构建coroutine（parse_lings(), fetch(), work()）。 核心之处是组织管理异步的抓取任务，代码块结构如下： class Crawler: def __init__(self, roots, ....., loop): self.q = Queue(loop=self.loop) # 建立队列 @asyncio.coroutine def parse_links(self, response): '''从返回内容中解析出要抓取的链接''' body = yield from response.read() if response.status == 200: if content_type: text = yield from response.text() urls = set(re.findall()) for url in urls: if self.url_allowed(): links.add() @asynico.coroutine def fetch(self, url): '''访问链接，抓取返回结果''' while tries: try: response = yield from self.session.get(url) try: if is_redirect(): pass else: links = yield from self.parse_links(response) finally: yield from response.releas() @asyncio.coroutine def work(self): '''封装抓取过程，与队列交互''' try: while True: url = yield from self.q.get() assert url in self.seen_urls yield from self.fetch(url) self.q.task_done() @asyncio.coroutine def crawl(self): '''建立Tasks，启动Task''' workers = [asyncio.Task(self.work(), loop=self.loop) for _ in range(self.max_tasks)] yield from self.q.join() 下图是我对上述代码结构的理解： 对coroutine的进一步介绍，参见Coroutine-Generator-Async与Await。 A Web Crawler With asyncio Coroutines导读文章整体结构： 分析爬虫任务 传统方式：抢锁 异步方式的特点：无锁；单线程上同时运行多操作 回调函数：fetch(),connecte(),read_response()的实现 Coroutine Generator的工作原理 用Generator实现Coroutine Asyncio库中的Coroutine crawl() work() fetch(), handle redirections Queue() EventLoop() Task() Conclusion 文章最后，作者点明了主题思想： Increasingly often, modern programs are I/O-bound instead of CPU-bound. For such programs, Python threads are the worst of both worlds: the global interpreter lock prevents them from actually executing computations in parallel, and preemptive switching makes them prone to races. Async is often the right pattern. But as callback-based async code grows, it tends to become a dishevelled mess. Coroutines are a tidy alternative. They factor naturally into subroutines, with sane exception handling and stack traces. 大意是说，对I/O密集型的程序，Python多线程在两方面令人失望：全局锁的设定使之不能真正并行；抢占式多任务处理机制又让多个线程间形成竞争关系。异步通常是正确的选择。但持续增长的回调函数会使代码丧失可读性，Coroutine便是一种保持整洁性的替代方案。 拾遗这样说，Python的多线程效率带来的提高只是Python程序抢占了系统中非Python进程的资源（参考召集一波狐朋狗友帮你抢选修课），多个线程提高了Python作为一个整体在系统资源调配中的竞争力。 @ddlee","categories":[{"name":"Programming","slug":"Programming","permalink":"http://blog.ddlee.cn/categories/Programming/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://blog.ddlee.cn/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"http://blog.ddlee.cn/tags/爬虫/"}]},{"title":"Feedly+Reeder3+FeedMe:信息获取与处理","slug":"Feedly-Reeder3-FeedMe-信息获取与处理","date":"2017-04-03T03:13:37.000Z","updated":"2017-06-15T05:49:43.310Z","comments":true,"path":"2017/04/03/Feedly-Reeder3-FeedMe-信息获取与处理/","link":"","permalink":"http://blog.ddlee.cn/2017/04/03/Feedly-Reeder3-FeedMe-信息获取与处理/","excerpt":"","text":"我蛮早就意识到自己被信息淹没了。于是关了票圈，屏蔽了空间，不装任何新闻APP，失去效力的微信群一概不留，知乎上的关注也缩减了很多很多。 世界终于清静了。 但仍然需要有关注的动向。我又捡起了RSS这个老朋友，建立起的信息获取跟处理流如下图： 服务与APP主要涉及的服务：Feedly（免费，有高级版） IOS APP： Reeder3（￥30） Pocket（免费） Pushbullet（免费） Evernote（免费版限制客户端个数） Android APP: FeedMe（免费） Pocket Inbox Evernote Google Keep 获取：Feedly整合Feedly是著名的信息聚合服务，能从媒体RSS、博客、YouTube Chanel等拉取文章/动态，还提供Google关键词动态提醒服务。 这里先推荐两个Chrome插件，可以更方便地将网页端想要订阅的信息整合到Feedly中。 Follow Feed: 识别跟当前网页内容相关的信息源，添加到Feedly订阅中。 Save to Feedly Board: 将当前网页添加到Feedly Board中，可以标记后分享给团队，实时更新。 信息源微信公众号先直接在Feedly中搜索公众号，若找不到订阅源，则可通过微广场等服务转成RSS。 媒体/博客RSS源很多在线媒体会在主页提供RSS地址，也可直接在Feedly中搜索媒体名。 知乎专栏有些工具可以将知乎专栏转成RSS订阅源。 关键词Feedly支持设置关键词动态提醒。 处理：Reeder3 + FeedMe支持Feedly的APP实在太多，这里是官方给出的列表，可看脸挑选。 我平常同时用Android和IOS处理订阅的信息，大屏精读，小屏浏览。 IOS: Reeder3不幸的是Reeder3是要付费的， 30块，几乎没有降过价。 替代品可以考虑自家的Feedly，Ziner等，可以参考这篇文章对比的结果选择。 Android: FeedMe这里强推FeedMe(Google Play)，抓取、缓存迅速，界面简洁，还有“中国大陆”模式。 消化：Pocket, Inbox, Evernote/Keep我个人将信息处理的结果分为三类： Read Later: 没消化 Links to save: 还想接着吃 Favorite: 想学着做 稍后再读用Pocket，接口丰富，功能专一（尽管也有了“发现”模块）。 文章中挂的一些外链，移动端不好处理，要发往PC，手机端存在Inbox中，当临时的标签栏，iPad端用Pushbullet发给Chrome，下次打开Chrome时浏览处理。 收藏的文章存到Evernote，打好tags，长篇干货/可反复参考的转到OneNote。 拾遗其他情境下遇到的好文章、信息等尽量文字存到Google Keep，链接存到Inbox，或者给自己写封邮件。 微信的Favorite尽量不用，收藏的目的就在于情景分离，在不同的上下文中，我门信息获取的效率和质量区别实在太大了。详情参考拉微信群异地参加美赛的战友们。 最后推荐几个不错的订阅源(右击复制链接)： SBNation上Mike Prada的文章: 对NBA比赛、球队战术的分析 Paper Weekly: 机器学习方面的论文解读 统计之都: 统计学及应用、R语言方面的优秀内容 GitHub Trends blog.ddlee.cn: 大言不惭 -_-！ @ddlee","categories":[{"name":"Individual Development","slug":"Individual-Development","permalink":"http://blog.ddlee.cn/categories/Individual-Development/"}],"tags":[{"name":"Individual Management","slug":"Individual-Management","permalink":"http://blog.ddlee.cn/tags/Individual-Management/"},{"name":"RSS","slug":"RSS","permalink":"http://blog.ddlee.cn/tags/RSS/"}]},{"title":"网站迁移小记：腾讯云+Debian+Vestacp","slug":"网站迁移小记：腾讯云-Debian-Vestacp","date":"2017-04-01T17:11:05.000Z","updated":"2017-04-05T13:12:58.824Z","comments":true,"path":"2017/04/02/网站迁移小记：腾讯云-Debian-Vestacp/","link":"","permalink":"http://blog.ddlee.cn/2017/04/02/网站迁移小记：腾讯云-Debian-Vestacp/","excerpt":"","text":"先贴一张文章大纲。 这是一个樱花开得正好但我很蛋疼的下午。 中午抢到了腾讯的校园优惠，便打算把网站ddlee.cn迁到国内的服务器上来。 密码管理先谈密码管理。 建站会涉及设置很多密码，之前明文保存在云笔记里的方案总觉得又土又笨，何况很多密码最好要随机生成，密码管理服务还是必要的。 搜索之后，我选择的是lastPass。主要考虑了免费和跨平台的特性。有更高要求的建议选择付费的1Password。 需要安装Chrome插件和Ubuntu下的deb包，添加Secure Note的功能深得我心，也支持自定义模板。 主机腾讯云的校园优惠力度很大。阿里云是9.9块/月，腾讯用完券1块/月。 这里多讲一句，学生真是幸福得不得了。GitHub Education Pack中既有有Digital Ocean的优惠，AWS也有150刀的礼品卡，Jetbeans大部分产品免费……这还不提学校里买的License。 腾讯的主机1核CPU，2G内存，20G系统盘（Linux），挂个网站还算够用。 SSH Key 配置建议在配置主机前创建一个SSH Key，这样访问起来安全又省心。 Linux系统下，在~/.ssh/下新建config，写入如下类似内容： Host Name HostName Host_IP User root IdentityFile path/to/ssh_private_key 这样就可以通过命令ssh Name直接访问主机。 系统选择建议选择Linux主机。具体哪一系可自行选择，我的选择是Debian，CentOS也是个不错的选择。 安全组设置建议先只开启用于SSH的22端口，之后再开HTTP访问的80端口，FTP的20,21端口和主机面板所用端口。 如果个人有代理服务器的话，也可以限制一下来源IP，这样可以通过登入代理服务器，在代理服务器上通过SSH登入WEB主机，需要迁移下SSH Private Key，可以通过命令scp usr1@host1:/path1 usr2@host2:/path2实现。 网络环境LNMP和LAMP是两种流行的结构。可以分别安装，再配置相应的config，也可以搜索得到很多一键安装脚本。另一种方案是用Docker部署。 我懒而笨，选择的是用主机面板一键安装。 主机面板在此之前，一直用的是AMH的免费4.2版本，简洁轻巧，功能也够用。付费版推出后，免费版遭到冷落，几乎没有更新，这如何能忍。 说起主机面板，我的启蒙是WDCP，其远古风格的UI仍历历在目，后来听说爆出漏洞，但那时我已转战AMH。 一番艰苦卓绝的搜索之后（其实就是检索了’best host control pannel’），我选择了Vestacp。 UI漂亮，功能不缺（建站，MAIL，备份），GitHub还算活跃，就决定是你了。 缺点是文件管理器收费，不能通过WEB管理文件。安装过程持续蛮久（半个小时，当然也包括了新主机系统包更新的时间）。 安装时注意Hostname填写IP或者已经配置好DNS解析的域名（如admin.ddlee.cn）。8083是管理面板的端口，记得在主机提供商的安全组里开放一下。 建站Vestacp支持多人管理，User身份由Package定义，安装过程会自动新建admin，拥有最高权限。 在User的设置里，可以配置用户的Package，而Package的设置里，可以配置每一用户身份的建站模板，资源上限等。如图。 建站相当容易，注意在高级选项里添加FTP账户，用于之后上传HTML文件。 FTP建站完成后，记得配置好DNS解析，开放20和21端口，就可以用FileZilla测试链接。 注意，在高级选项里配置好Default local directory，设置Default remote directory为/public_html，并启用synchronized browsing和directory comparison，以后的FTP生活会很幸福。 Mail若在建站时勾选了Mail support，可以建立个性化的邮箱名，可以设置自动回复/转发，也可以用Gmail托管。以后留邮箱的时候可以短短的了呢。 配置SSL这是无意发现的技能。 本来在我的印象里，SSL证书都是要收费的。但留心的朋友可能注意到，建站时SSL support下有Lets Encrypt Support。这一服务可以用上免费的SSL。 官网：Let’s Encrypt 要利用这项服务，需要证明自己对网站的至高无上不可侵犯的神圣权利，方法之一是运行支持[ACME protocol]的Client，官网推荐了Cerbot。 在Cerbot主页可以选择自己的操作系统，会有详细的步骤，在此不表。 下面谈两个问题，一是强制重定向至HTTPS，二是取消管理端口的HTTPS。 强制HTTPSVestacp的架构是用nginx做proxy，Apache2做HTTP Server，首先下载nginx template（proxy template）： cd /usr/local/vesta/data/templates/web wget http://c.vestacp.com/0.9.8/rhel/force-https/nginx.tar.gz tar -xzvf nginx.tar.gz rm -f nginx.tar.gz 之后在Package配置里，将proxy template配置为force-https，这样，身份由相应Package定义的用户建站时，proxy template就是用的强制HTTPS版本了。 取消管理端口的SSL用chrome访问管理页面时，会有Unsecure的警告，这里的SSL在/usr/local/vesta/nginx/conf/nginx.conf中配置。找到 # Vhost server { listen 8083; server_name _; root /usr/local/vesta/web; charset utf-8; # Fix error &quot;The plain HTTP request was sent to HTTPS port&quot; error_page 497 https://$host:$server_port$request_uri; # ssl on; # ssl_certificate /usr/local/vesta/ssl/certificate.crt; # ssl_certificate_key /usr/local/vesta/ssl/certificate.key; # ssl_session_cache shared:SSL:10m; # ssl_session_timeout 10m; 将配置SSL的几行注释掉即可。顺便，管理页面的端口也可以在这里更改。之后运行service vesta restart重启服务。 域名与DNS最后简单提一下域名注册跟DNS。要注意的几个点： 国内域名注册要备案，很烦，但cn域名好便宜。 在域名注册商那里配置DNS解析服务器（万网、DNSPod都好，不一定用自建网站的DNS） 在DNS服务商那里添加解析记录，顺便开启监控 拾遗域名备案的时候，需要签一张备案单。方案是在纸上签字后调背景为透明，用Adobe PDF Reader的签字功能签好PDF，再转成JPG。 几项操作都可以通过在线工具完成，低碳生活，人人有责。 总结 建站过程本身就其乐无穷，教程一抓一大把，难的在TROUBLE SHOOTING，所以Google是最好的伴侣。 命令行、vi编辑、必要的WEB知识等是基础，在此感谢我们的墙两年前就教给我这些东西。 @ddlee","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://blog.ddlee.cn/tags/Linux/"},{"name":"云主机","slug":"云主机","permalink":"http://blog.ddlee.cn/tags/云主机/"},{"name":"Vestacp","slug":"Vestacp","permalink":"http://blog.ddlee.cn/tags/Vestacp/"},{"name":"博客迁移","slug":"博客迁移","permalink":"http://blog.ddlee.cn/tags/博客迁移/"}]},{"title":"The Devtools Way: devtools+RStudio快速R程序包开发","slug":"The-Devtools-Way-devtools-RStudio快速R程序包开发","date":"2017-03-31T05:50:13.000Z","updated":"2017-06-15T05:51:23.914Z","comments":true,"path":"2017/03/31/The-Devtools-Way-devtools-RStudio快速R程序包开发/","link":"","permalink":"http://blog.ddlee.cn/2017/03/31/The-Devtools-Way-devtools-RStudio快速R程序包开发/","excerpt":"","text":"本文记录我的首个R程序包MCMI的开发过程。 参考资料 两本Hadley Wickham写的书：Advanced R和R Packages。 Coursera上的课程Mastering Software Development in R Specialization和配套教材Mastering Software Development in R。 感谢开源社区，以上的资料都可以免费获取得到（Coursera课程可以申请补助）。 Preparation开发R包还需要系统中存在编译工具，编译文档需要LaTeX支持。 Linux用户：sudo apt-get install r-base-dev texlive-full Windows用户：1.RTools;2.MikTeX 另外，请确保以下两个包已安装于系统中：devtools和roxygen2。推荐使用RStudio。 Get Started在RStudio中新建项目，选择R程序包类型即可。建议同时建立Git路径以监控开发流程。 在编写代码之前，先要修改DESCRIPTION文件，要注意的几个地方： Package的命名要容易记忆和查询 Depends指你所用开发环境的R版本 慎重选择License Imports指你所要调用的其他包，但在代码中，也要明确指出函数所处的包，如ggplot2::qplot() Git Workflow建议在GitHub上为本机申请SSH密钥，并在RStudo-&gt;Tools-&gt;Global Options-&gt;Git/SVN配置好路径，这样在执行git push时不用再次输入凭据。下面是有关Git的工作流： 修改代码/文档 编译，测试 git commit git push 重复以上循环 RStudio对Git的集成很好，以上三四步操作均可在Git的操作面板里完成。 Code Workflow 修改代码 Build&amp;Reload 用命令行测试功能 重复以上循环 上述第二步可以在命令行中devtools::load_all()完成，也可以使用快捷键”Ctrl + Shift + L”，也可以在RStudio的开发面板中执行”Build&amp;Reload”命令。之后，便可在命令行中调用编写好的函数，验证其功能。 Documentation Workflow 在.R文件中添加roxygen注释 Document 使用help面板或?命令预览文档 重复以上循环 同样地，第二步有三种实现方式：1.devtools::document();2.”Ctrl + Shift + D”；3. RStudio开发面板中的”Document”命令。 Test Workflow测试方面，除了上述Coding Workflow中提到的在命令行中调用函数进行测试之外，还可以利用testthat包来使测试自动化。 首先要安装testthat包，再使用devtools::ust_testthat()命令建立testthat路径。 下面是自动化测试的工作流： 修改代码 在testthat路径下编写相应的测试语句 Build&amp;Reload Test 排除Bug，重复上述过程 以上流程第四步同样有三种实现方式：1.devtools::test();2.”Ctrl + Shift + T”;3.RStudio中开发面板的“Test”命令。 Release按照上述过程开发的R程序包，每一次git push事实上都是一次发布。使用devtools::install_github(&quot;git_repo_goest_here&quot;)命令，可以很方便地安装R程序包。 Next Step使用devtools配合RStudio和Git，开发R包的过程已经非常亲民和流水线化。但要开发高质量的R包，需要对R的数据结构和S3等对象系统有更深的理解，而Advanced R则是你通往这一方向的最好伴侣。","categories":[{"name":"Data Science","slug":"Data-Science","permalink":"http://blog.ddlee.cn/categories/Data-Science/"}],"tags":[{"name":"Data Science","slug":"Data-Science","permalink":"http://blog.ddlee.cn/tags/Data-Science/"},{"name":"Programming","slug":"Programming","permalink":"http://blog.ddlee.cn/tags/Programming/"},{"name":"R","slug":"R","permalink":"http://blog.ddlee.cn/tags/R/"}]},{"title":"HADOOP学习速记","slug":"HADOOP学习速记","date":"2017-03-30T14:22:02.000Z","updated":"2017-04-09T15:44:09.699Z","comments":true,"path":"2017/03/30/HADOOP学习速记/","link":"","permalink":"http://blog.ddlee.cn/2017/03/30/HADOOP学习速记/","excerpt":"","text":"HDFS: 分布式文件系统NameNode, DataNode: a MetaData-Data ModelStrategy: Block split, multi-copy, distribution NameNode: High Availabilitysolution 1: backup using NFSsolution 2: Two NameNodes(Active and Standby) MapReduce: 计算框架split -&gt; Process -&gt; aggregate Deamon: Job Tracker &amp; Task Tracker Design PatternCourse Project（未完待续）@ddlee","categories":[{"name":"AI","slug":"AI","permalink":"http://blog.ddlee.cn/categories/AI/"}],"tags":[{"name":"分布式计算","slug":"分布式计算","permalink":"http://blog.ddlee.cn/tags/分布式计算/"},{"name":"Data Sicence","slug":"Data-Sicence","permalink":"http://blog.ddlee.cn/tags/Data-Sicence/"},{"name":"Hadoop","slug":"Hadoop","permalink":"http://blog.ddlee.cn/tags/Hadoop/"}]},{"title":"Kaggle比赛中EDA：流程、做法与目的","slug":"Kaggle比赛中EDA：流程、做法与目的","date":"2017-03-26T11:09:00.000Z","updated":"2017-04-02T17:47:54.245Z","comments":true,"path":"2017/03/26/Kaggle比赛中EDA：流程、做法与目的/","link":"","permalink":"http://blog.ddlee.cn/2017/03/26/Kaggle比赛中EDA：流程、做法与目的/","excerpt":"","text":"数据集大小、字段及相应的数据类型 大小：占用内存估计 字段数：维度估计，是否需要降维 数据类型：numerical, factor, string, etc. 是否需要归一化，二元化等等 了解数据的缺失值情况及分布了解数据分布情况，可用众多图形完成 bar plot histogram violin plot box plot scatter plot 主要目的： 了解整体状况，是否具有野点 结合目标变量，考察特征与目标变量间的相关性 文本数据常用的探索： 词频统计（消除stopwords之后） 词云 后记本来文章是从几个经典的EDA notebook开始，试图总结出其共性之处，但写来写去，总觉得随便一本跟数据分析相关的书中，探索性数据分析的章节也大概都会涉及到这些内容，但在读书的情景之下又难留下深刻的印象，做分析的真正见地与经验，还是要从实践中来啊。 @ddlee","categories":[{"name":"Data Science","slug":"Data-Science","permalink":"http://blog.ddlee.cn/categories/Data-Science/"}],"tags":[{"name":"Kaggle","slug":"Kaggle","permalink":"http://blog.ddlee.cn/tags/Kaggle/"},{"name":"EDA","slug":"EDA","permalink":"http://blog.ddlee.cn/tags/EDA/"},{"name":"Data Sciencce","slug":"Data-Sciencce","permalink":"http://blog.ddlee.cn/tags/Data-Sciencce/"},{"name":"笔记","slug":"笔记","permalink":"http://blog.ddlee.cn/tags/笔记/"}]},{"title":"Udacity课程： Intro to DevOps侧记","slug":"DevOps侧记","date":"2017-03-22T15:19:07.000Z","updated":"2017-04-05T13:13:11.605Z","comments":true,"path":"2017/03/22/DevOps侧记/","link":"","permalink":"http://blog.ddlee.cn/2017/03/22/DevOps侧记/","excerpt":"","text":"文章主要内容来自Udacity的课程：Intro to DevOps CAMS: The DevOps LifecycleThe Purpose of DevOps： 产品、开发、运维之间的协作问题 Definition(from wiki) a set of practices that emphasize the collaboration and communication of both software developers and information technology (IT) professionals while automating the process of software delivery and infrastructure changes. (Source) 对比： Agile Development（敏捷软件开发） Plan-&gt;Code-&gt;Test-&gt;Release-&gt;Deploy-&gt;Operate Means of CAMS C: Culture A: Automation M: Measurement S: Sharing The DevOps EnvironmentSolving the Environment Problem: Golden Image: apps-libs-OS Configuration Management Course Project（使用Golden Image方案，引入一批DevOps工具)dependencies-&gt;build scripts-&gt;tests-&gt;web apps PackerPacker is an open source tool for creating identical machine images for multiple platforms from a single source configuration. Artifacts are the results of a single build, and are usually a set of IDs or files to represent a machine image. Builds are a single task that eventually produces an image for a single platform. Builders are components of Packer that are able to create a machine image for a single platform. Commands are sub-commands for the packer program that perform some job. Post-processors are components of Packer that take the result of a builder or another post-processor and process that to create a new artifact. Provisioners are components of Packer that install and configure software within a running machine prior to that machine being turned into a static image. Templates are JSON files which define one or more builds by configuring the various components of Packer. Example JSON File VagrantVagrant is a tool for building complete development environments. With an easy-to-use workflow and focus on automation, Vagrant lowers development environment setup time, increases development/production parity, and makes the “works on my machine” excuse a relic of the past. Project Workflow: Packer-&gt;Vagrant-&gt;Virtualbox-&gt;Web ApplicationPart I: Building a box with PackerFrom the packer-templates directory on your local machine: Run packer build -only=virtualbox-iso application-server.json Troubleshooting: Find the newest version number and checksum from the Ubuntu website for this releaseEdit PACKER_BOX_NAME and iso_checksum in the template files to match that version number and checksum. Run cd virtualbox Run vagrant box add ubuntu-14.04.4-server-amd64-appserver_virtualbox.box --name devops-appserver Run vagrant up Run vagrant ssh to connect to the server Part II: Cloning, developing, and running the web application On your local machine go to the root directory of the cloned repository Run git clone https://github.com/chef/devops-kungfu.git devops-kungfu Open http://localhost:8080 from your local machine to see the app running. In the VM, run cd devops-kungfu To install app specific node packages, run sudo npm install. You may see several errors; they can be ignored for now. Now you can run tests with the command grunt -v. The tests will run, then quit with an error. On Cloud platformSimilar commands using packer: packer build -only=amazon-ebs &lt;server-name&gt;.json packer build -only=googlecompute application-server.json Continuous Integration（持续集成）CI System: JenkinsJenkins is a self-contained, open source automation server which can be used to automate all sorts of tasks such as building, testing, and deploying software. Using command:packer build -only=&lt;cloud service target&gt; control-server.json Example control-server.json file Jenkins was configured to be installed according to Provisioners. After building and launching, access Jenkins via URL /jenkins. Testing（测试，QA） Unit Testing Regression testing Smoke testing System Integration testing Automate acceptance testing Manual QA testing Adding Manual QA step in Pipeline MonitoringMonitoring process: Additional ResourcesCourse Wiki 小结DevOps从开发和运维合作的角度审视软件开发过程，并提供了一套方法论，涉及开发、测试、部署、维护、监测各个方面。软件行业，不仅仅是写代码而已。 @ddlee","categories":[{"name":"Internet","slug":"Internet","permalink":"http://blog.ddlee.cn/categories/Internet/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ddlee.cn/tags/DevOps/"},{"name":"技术","slug":"技术","permalink":"http://blog.ddlee.cn/tags/技术/"}]},{"title":"Python与SQL_Server的交互：pyODBC, pymssql, SQLAlchemy","slug":"Python与SQL_Server的交互：pyODBC, pymssql, SQLAlchemy","date":"2017-03-16T14:57:37.000Z","updated":"2017-04-05T13:13:08.948Z","comments":true,"path":"2017/03/16/Python与SQL_Server的交互：pyODBC, pymssql, SQLAlchemy/","link":"","permalink":"http://blog.ddlee.cn/2017/03/16/Python与SQL_Server的交互：pyODBC, pymssql, SQLAlchemy/","excerpt":"","text":"Windows平台下Python读取、写入SQL Server相关的函数库，文章结构如下： Python DriversPyODBCAnnaconda下可以用pip install pyodbc安装，也可以到这里下载。 首先建立connection对象： import pyodbc conn = pyodbc.connect( r'DRIVER={ODBC Driver 11 for SQL Server};' #or {ODBC Driver 13 for SQL Server} r'SERVER=ServerHostName;' r'DATABASE=DBName;' r'UID=user;' r'PWD=password' ) 添加游标（Cursor）对象并执行SQL查询语句： cursor = conn.cursor() cursor.execute('SQL Query Goes Here') for row in cursor.fetchall(): print(rows.[column name]) 更多信息参见MSDN DOCs。 pymssql同样可以用pip install pymssql安装，也可以到这里，然后用pip安装wheel文件。 pymssql目前还不支持Python3.6，这点要注意下。 pymssql的用法跟pyODBC很像，下面是官网给出的例子： from os import getenv import pymssql server = getenv(\"PYMSSQL_TEST_SERVER\") user = getenv(\"PYMSSQL_TEST_USERNAME\") password = getenv(\"PYMSSQL_TEST_PASSWORD\") conn = pymssql.connect(server, user, password, \"tempdb\") cursor = conn.cursor() cursor.execute(\"\"\" IF OBJECT_ID('persons', 'U') IS NOT NULL DROP TABLE persons CREATE TABLE persons ( id INT NOT NULL, name VARCHAR(100), salesrep VARCHAR(100), PRIMARY KEY(id) ) \"\"\") cursor.executemany( \"INSERT INTO persons VALUES (%d, %s, %s)\", [(1, 'John Smith', 'John Doe'), (2, 'Jane Doe', 'Joe Dog'), (3, 'Mike T.', 'Sarah H.')]) # you must call commit() to persist your data if you don't set autocommit to True conn.commit() cursor.execute('SELECT * FROM persons WHERE salesrep=%s', 'John Doe') row = cursor.fetchone() while row: print(\"ID=%d, Name=%s\" % (row[0], row[1])) row = cursor.fetchone() conn.close() 详细用法参见pymssql docs和MSDN DOCs SQLAlchemy(Python SQL Toolkit)SQLAlchemy提供了一系列丰富、完整、（我看不懂）的API用于数据库操作。这里只谈其create_engine方法。 from sqlalchemy import create_engine # pyodbc engine = create_engine('mssql+pyodbc://user:password@DSNname') #需要配置DSN，参见最后一节 # pymssql engine = create_engine('mssql+pymssql://user:password@Hostname:port/DBname') 利用创建好的engine，可以结合pandas库进行批量的读取、写入操作。 用SQLAlchemy与其他类型的数据库建立链接的方法参见这里。 Pandas利用pyODBC和pymssql拉取的对象需要进一步处理才能进行常见的数据清洗等工作，而Pandas也提供了SQL相关的方法，在SQLAlchemy的辅助下，可以将DataFrame对象直接写入table。 读取：pd.read_sql()API： pandas.read_sql(sql, con, index_col=None, coerce_float=True, params=None, parse_dates=None, columns=None, chunksize=None) 其中的con参数，可以传入SQLAlchemy建立的engine对象，也可以是pyODBC或者pymssql建立的DBAPI2 connection对象。 写入:pd.DataFrame.to_sql()API: DataFrame.to_sql(name, con, flavor=None, schema=None, if_exists='fail', index=True, index_label=None, chunksize=None, dtype=None) 这里的con参数，只支持sqlite3的DBAPI2 connection对象，支持所有的SQLAlchemy engine对象。name参数传入表名，用if_exists参数控制表存在时的动作： ‘fail’: 啥也不干。 ’replace‘: 将原有表删除，新建表，插入数据。 ’append&#39;: 在表中插入数据。表不存在时新建表。 命令行利用Sqlcmd命令，也可以在命令行下执行SQL文件，用法如下： sqlcmd -U user -P password -S server -d DBName -i /path/to/myScript.sql 这样可以有如下思路，将数据写入.SQL文件，再生成.bat文件（批量）写入上述命令，之后完成执行。 DSNWindows下可以配置DSN(Data Source Names)预先存储数据库连接的信息，在Control Panel -&gt; Administrative Tools -&gt; ODBC Data Source 下添加即可。 配置好DSN后，pyODBC的连接过程可以简化为： conn = pyodbc.connect(r'DSN=DSNname;UID=user;PWD=password') #UID和PWD也可以在DSN中配置 拾遗Python与文件的IO、SQL数据库的读写时有中文字符可能会有编码问题。一种方案是在中文字符串前添加N，如N&#39;python大法好&#39;；另一种方案是传入encoding参数，常用的中文编码有GB2123，GB18030，推荐的还是统一用UTF-8编码、解码。 利用如下命令，可以在SQLAlchemy中指定编码： engine = create_engine('mssql+pymssql://user:password@HostName\\DBname', connect_args = {'charset':'utf-8'}) 其他自定义DBAPI connect()参数的方法参见这里。","categories":[{"name":"Data Science","slug":"Data-Science","permalink":"http://blog.ddlee.cn/categories/Data-Science/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://blog.ddlee.cn/tags/Python/"},{"name":"SQL","slug":"SQL","permalink":"http://blog.ddlee.cn/tags/SQL/"},{"name":"数据库","slug":"数据库","permalink":"http://blog.ddlee.cn/tags/数据库/"}]},{"title":"再次折腾我的WNDR4300：OpenWrt文件共享","slug":"再次折腾我的WNDR4300","date":"2017-03-12T07:00:25.000Z","updated":"2017-04-03T04:31:29.756Z","comments":true,"path":"2017/03/12/再次折腾我的WNDR4300/","link":"","permalink":"http://blog.ddlee.cn/2017/03/12/再次折腾我的WNDR4300/","excerpt":"","text":"生命不惜，折腾不止。 缘起再次成为IOS用户后，访问Google和文件共享成了两大需求。问题出现了，就要解决，于是有此文记录的活动。 重新安装OpenWrtOpenWrt已经到了15.05版本，版本代号是Chaos Calmer。重装需要的-factory.img，可以在这里下载。 我的WNDR4300平台是ar71xx，可以从OpenWrt对应的硬件主页找到固件镜像文件。 TFTP重装如果你的路由器还是出厂系统的话，可以通过登入后台在线上传镜像文件进行刷机，而我的已经是OpenWrt系统，只能通过网页端升级，故选用了TFTP方式刷机。 刷机步骤摘自OpenWrt wiki &gt; set a static IP on your computer, i.e 192.168.1.35, and connect the ethernet cable to the router power on the router press and hold the RESET button as soon as the switch LEDs light up. keep holding RESET until the power LED begins to flash orange and then green. once the power LED is flashing green, release RESET start the TFTP transfer to router at 192.168.1.1. In your computer execute:tftp 192.168.1.1 -m binary -c put factory.img 总体来说是分为三步： 将电脑与路由器设置在同一内网中 令路由器进入恢复模式 利用TFTP将刷机包推入路由器 U盘挂载，文件共享安装好OpenWrt后，就可以从网页端访问路由器，设置PPPoE拨号，设置WIFI等等。 U盘挂载U盘挂载部分主要参考了跟 UMU 一起玩 OpenWRT（入门篇6）：挂接 U 盘。 首先是安装相应的包： opkg update # 核心包 opkg install kmod-usb-storage opkg install kmod-scsi-generic # 文件系统 opkg install kmod-fs-ext4 # 辅助工具 opkg install usbutils fdisk e2fsprogs 利用lsusb命令查看U盘是否已经被路由器识别。 这时可以选择用fdisk进行重新分区，不需要分区的话，可以用命令ls /dev | grep sd查看/dev分区中是否已经出现U盘。 在OpenWrt上使用U盘，建议用ext4格式，可以用下面的命令进行格式化： # sda1为上一命令得到的结果 mkfs.ext4 /dev/sda1 接下来就可以用mount命令进行挂载了： # 路径/mnt/usb/即为挂载目标点 mkdir /mnt/usb touch /mnt/usb/USB_DISK_NOT_PRESENT chmod 555 /mnt/usb chmod 444 /mnt/usb/USB_DISK_NOT_PRESENT mount /dev/sda1 /mnt/usb 这时可以测试一下，如果U盘里面存储了文件，可以通过/mnt/usb访问的到。 下面是开机自动挂载U盘的命令。 # block-mount blkid用于查看U盘的UUID opkg install block-mount blkid # 实际上要操作的是fstab的配置文件/etc/config/fstab，要将enabled值改成1 block detect > /etc/config/fstab uci set fstab.@mount[-1].target='/mnt/usb' u ci set fstab.@mount[-1].enabled=1 uci commit fstab 更详细的信息可以参见这里 文件共享文件共享可以通过FTP和SAMBA，推荐的方式是SAMBA。 SAMBA安转SAMBA： opkg update opkg install samba36-server # luci程序，可选 opkg install luci-app-samba 安装好SAMBA后，主要配置两个参数，一是共享文件夹的路径，如/mnt/usb/sambashare，可以通过更改配置文件/etc/samba/smb.conf实现，也可以通过luci实现。 示例： [sambashare] path = /mnt/usb/sambashare valid users = root read only = no guest ok = yes create mask = 0750 directory mask = 0750 第二个参数是访问账户，可以通过命令sambpasswd -a将你的当前用户加入到SAMBA的组中，需要设置一个密码。另外，可能需要将配置文件/etc/samba/smb.conf的[global]中的invalid users = root注释掉。 最后，设置SAMBA服务启动和开机自启 /etc/init.d/samba start /etc/init.d/samba enable FTPFTP可以用vsftpd包来设置，大致过程与SAMBA类似：设置路径、添加用户、设置自启。 SAMBA服务可以在Windows文件资源管理器中自动检测的到，Linux下可以通过smb://Host/sharepath访问，在IOS系统中，类似Documents的应用也支持添加SAMBA的功能。 这里强推一下Documents这个应用，结合PDF EXPERT，已经成为了我的文档中心。 访问Google这部分操作相当复杂，主要参考这里，感谢博主。 后记这天的活动，本来只有我和上帝知道，再过一个月，就只有上帝知道了。遂作笔记。 @ddlee","categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.ddlee.cn/categories/Linux/"}],"tags":[{"name":"OpenWrt","slug":"OpenWrt","permalink":"http://blog.ddlee.cn/tags/OpenWrt/"},{"name":"路由器","slug":"路由器","permalink":"http://blog.ddlee.cn/tags/路由器/"}]},{"title":"谁会不厌其烦地安慰那无知的少年（三）","slug":"谁会不厌其烦地安慰那无知的少年-3","date":"2017-03-03T15:41:10.000Z","updated":"2017-04-02T17:48:51.599Z","comments":true,"path":"2017/03/03/谁会不厌其烦地安慰那无知的少年-3/","link":"","permalink":"http://blog.ddlee.cn/2017/03/03/谁会不厌其烦地安慰那无知的少年-3/","excerpt":"","text":"年轻的时候可以随随便便喜欢一个人，可千万别真动情。那样的话你的余生就剩两种状态了，一种叫做想她，另一种是为克制自己想她而努力。——丁丁前舍友 丁丁的舍友告诉他，那年不懂事，一直陷于人生的错觉之中。 他觉得那女生好像喜欢她，做什么事儿都是像在针对他，总是跑来问问题呀，不懂的时候卖个萌啊，连谢谢的话都是奶声奶气的。 可他怎么能被这个给连累了呢。 他可是老师眼中最有希望的学生，早熟的他也明白合适的平台对自己的发展是多么重要。他觉得在人生的一段时间内能单纯地为一个目标而奋斗是一件幸福的事儿，任何分心的想法都是罪恶。 他在开始之前，就故作冷漠，就像结束了之后想要挽回那样。 丁丁插着话问到底什么开始什么结束的啊？ 舍友答，年少的初恋啊我的旁友！ 舍友顿了顿，眼里含着惋惜。 讲真，我是那种动情就会倾其所有的人，我真真觉得一生就只够爱一个人。但让我从没想到的是，我的故作冷漠才是动情的开始啊。 那时候我千方百计地回避她。 我特别跟组里的同学换了座位，这样就能离她远一点。 问题的时候我也爱搭不理的，不是把她推给别人就是拖着藏着。 她也算知趣，渐渐的就不来烦我了。 就这样吧，高考完了以后，我们去了不同的学校，离得八十万杆子都打不着。 但我逐渐的发现，这颗种子，已经在我的心底长成了参天大树，不管我给它什么样的脸色，它还是生长起来了。 我再也不能回避它了，我再也不能隐藏它了。 我以前听人家说暗恋一个人的时候，把她的动态错过都会有罪恶感。 我细细的品味她的日志、说说里流露出来的情感，挖空心思复原她写下这些文字时的心情，然后小心翼翼地写下我的评论，斟酌一下，再发表。然后就是每隔几个小时就刷一下，看看她回复了没有。 我也找她聊天，谈心，新的生活还适应没，高数有哪些不懂的跟我说说。 我也跟她讲我的近况，我在听什么歌，我在读哪些书。 可我从来都不敢表露我真实的心意，我也从来不敢提高中时候我的那段冷漠的时光。 可是，你知道吗，就跟吃巧克力一样，她吃到了苦的，我却吃了块甜的，德芙，带榛果颗粒的。 我终于等到了一个机会——她生病住院了。 急性胃炎，但她没跟我说，她的闺蜜告诉我的。 我买了票，赶到她所在的城市，在一个下着小雨的傍晚。 行人匆匆，从四面赶往八方。风催着云，一来一回地玩弄着月亮，雨打在肩上，我才知道我还没有方向。 我给她打电话，说我来看你来了，你在哪家医院。 她说你怎么来了，她已经快好了，明天就要出院，那你过来吧，在江东北路的那家人民医院，8号楼，324。 我说没事儿，马上就到。 不过地铁并不方便，只能在珠江路那里下，我就打算骑ofo过去。 然而我还是太年轻了，南方的冬天下着雨，可没那么好欺负，找路，问路，手冻僵，衣服也淋湿了，我想着张士超华师大的姑娘真的那么可爱吗。 等我赶到时，已经是需要照顾的人了，一副洋葱模样，就剩一层一层剥开了。 狼狈的我跑到厕所里，等个没人的空档，用烘干机吹了吹头发，把外套脱下来搭在胳膊上，这才往病房赶去。 丁丁的舍友推了下眼镜，接着说。 你可知道什么叫近乡情更怯呀，就跟查高考成绩一样啊，你再往前一步，就把那些想象过的所有美好的可能性全破除了，木已成舟，一切皆不可挽回，尽管，尽管你不往前一步，一切也早就注定了呀。 我在病房门前愣住了，万一里面还有人怎么办，她的同学在晚上应该会陪她吧，她不会有男朋友了吧？ 我跑到离门远一点的地方，又给她打了个电话，我说我快到了，你有什么想吃的我给你带点。 她说不用了，你过来就好，她也想赶快见到我。 我说好的，这么突然出现，没赶上不方便的时候吧。 她说没事儿，你直接过来吧，哪有什么方便不方便的。 挂了之后，我在楼里瞎逛了几圈，顺手把紧急逃生的路线考察了一下，发现还是很科学的，指引也做的很到位。估摸时间差不多了，我就敲门进去了。 她留起了长发，比高中的时候成熟不少，但终归有病在身，脸色有些发白，不过酒窝还是那样可爱。 我们聊起来，从病情开始，一直聊到那些在网易云音乐的歌曲下面刷评论的考研党们到底考上了没。 她似乎很开心，我也很开心。 她说上了大学就没跟别人聊这么久过，还是以前的同学好呀。 我说那当然了，以后有什么事你第一个告诉我。 要走的时候，她说谢谢我这么大老远地跑过来，不过病差不多要好了，明天亲自到车站送送你。 我说不用了，我自己走就行，你好好养着身体吧，注意一下饮食。 离开医院 ，我随便找了家旅馆住下来。心底里无限的舒适与满足。但很快，紧张与自责将我包裹起来。 太懦弱了我真是，聊那些没什么用的干啥，我该直接跟她说我喜欢你三年了我们在一起吧。 可又转念一想，这也有点趁人之危吧，还是等等再说？ 这一等就是一夜，我慢慢睡着，天刚刚破晓。 第二天，她还是来送我了，下地铁后，她用手机看了下时间，说还不晚不用着急。 她竟然用的Xperia。我心想我喜欢的女孩子就是有格调。 然后我就看到了手机桌面上男孩子的傻笑。 那个男孩子似乎不是我，我笑的时候不傻，眼睛眯成一条缝。 我说这也不早了你赶紧回去吧。 她说你开玩笑呢这才几点啊。 我说不对，我不是这个意思，我是说你不用跟我一起等了，我自己等，我自己能行。 她告诉我她当然相信我能行，不然怎么能自己跑过来看她呢。 我说也是哈，我这么催你干哈。 后面的事情我自己也记不清了。 回来的时候，出站换乘，转角碰见一家鲜花店，就进去买了一束满天星，捧着它回到寝室，摆在桌上。 我是眼睁睁地看着那一束花慢慢枯萎的。 不插在水中的话，只用了三天不到。 舍友说我那三天跟个傻逼一样。 后来她说我是她最好的朋友，跟高中的那个我完全不一样了。 原来她从来就没喜欢过我，而我也从来没承认过我那么心动，但你知道吗？这的的确确发生了。 舍友觉得可以做结了，便说出了这句丁丁永生难忘的话。 年轻的时候可以随随便便喜欢一个人，可千万别真动情。那样的话你的余生就剩一种状态了，那就是想她。 丁丁说没事儿你还有机会，天下没有不散的筵席，他们迟早会分的。 舍友说丁丁是傻逼。 ————————————————全文完————————————————— 我不再强说上面的故事是瞎编的了。它们是丁丁亲口告诉我的，在一次卧谈会上。 丁丁说在刚好记得的时候讲出来，其实是自私的。 他说他从小到大失去了很多人，从每天早到学校开门的劳动课老师到害了白血病的不幸前桌，从打架斗殴满嘴义气话的小魔王到奔走他乡借读名校的竞争对手，当好友列表里的灰色头像终于不再跳动的时候，我就不再是完整的了，他们把我的一部分带走了，而且永远找也找不回来了。这个永远是真的。 我跟丁丁说你错了，你不知道更可怕的事情。你有没有想过，即使是陪你一起长大的人，也有很多东西找不回来了。像你的父母，你的淘气和无知，早就淹没在他们眼角的层层皱纹里了。而且，是你亲手把它们埋葬进去的。你看，谁都没有失去谁，谁也失去了谁。 丁丁说是啊，我们都变了，变得都有些记不起从前的样子了。人们总是到失去了才懂得珍惜，这真是瞎话，我们就从来没有拥有过。 我记起很久以前的一个秋天，我打开了一册我昔日嗜爱的书读了下去，突然回复到十四岁时那样温柔而多感，我在那里面找到了一节写在发黄的纸上的以这样两行开始的短诗： 在你眼睛里我找到了童年的梦，如在秋天的园子里找到了迟暮的花…… @ddlee 2017年3月","categories":[{"name":"随笔","slug":"随笔","permalink":"http://blog.ddlee.cn/categories/随笔/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"http://blog.ddlee.cn/tags/随笔/"}]},{"title":"谁会不厌其烦地安慰那无知的少年（二）","slug":"谁会不厌其烦地安慰那无知的少年-2","date":"2017-02-15T12:51:08.000Z","updated":"2017-04-02T17:48:41.018Z","comments":true,"path":"2017/02/15/谁会不厌其烦地安慰那无知的少年-2/","link":"","permalink":"http://blog.ddlee.cn/2017/02/15/谁会不厌其烦地安慰那无知的少年-2/","excerpt":"","text":"不要做父母手中的烤鸭，要做一只自由的小小种马。——刘星，《（假的）家有儿女》 丁丁再回到这条老街时，又是一年的光景。 这一年，家乡添了几处新房和俏媳妇，添了几家麻将交流中心，添了几座坟头。 村后的河今年却冻住了——往年不上冻的，因为里面东西太多。 村前公路两旁的树全砍掉了。主人缺钱，不缺树。 目力所及，坑洼的油漆路向北延伸到省道上，两旁田地里丛丛的麦子依偎而息，灰蒙蒙的天，树林间掩映着冬日里小姑娘红扑扑的脸蛋，那是北方的夕阳。哎呦，还蒙了层雾气。 这次回老家，丁丁照例去拜访过道尽头被奶奶称为”二嫂“的老太太。 二嫂是帝都过来的知青，这些年没入我们的乡音，跟谁也是一口侉侉的北京话。 她最著名的话是，“我主的了疼，也主的了管”。 这是跟人家解释为什么老打孙子。一时成为村里溺爱孙子老传统中的一股清流。 可老人家现在状态不好：去年初四，脑出血，救回来之后半边失去了控制，歪了嘴，动不了腿。 我进了门，走到轮椅边。老人眼睛亮了起来，一只手撑着扶手，要站起来。 我大声说奶奶您不用起来，多累啊。 二嫂摇着头坐下，攥着我的手，晃来晃去。又赶紧把暖手袋扯过来，叫我捧着。 就像小时候那样。 二嫂是看着我长大的。奶奶经常带着我到二嫂家里串门，二嫂家里有糖吃，有奶喝。 那时候我最喜欢翻彻二嫂厚厚的影集，上面有好多我没见过的东西。 奶奶你耳朵边别着的是什么花呀，那时候你几岁。 二嫂说那年她十六，别着的花叫白玉兰。 今年她七十六。照片上的小姑娘带一点自信，含一丝羞赧，就像每个十六七岁的女孩子那样。 这让我想起妈妈。妈妈年轻的时候追邓丽君、小虎队，最喜欢的是粉红色的回忆。家里有一张她结婚时的照片，大红毛衣，傻傻的杵在那里，另一头爸爸给二叔骑在背上，向妈妈鞠躬，胸前歪着一朵大红花。 我没见过作为年轻姑娘的二嫂和妈妈是什么样子的，跟我相关的，只有她们逐渐老去的岁月。 二嫂晃动着身子，她打算站起身来。 我扶着她，走一步，拖一步，不违背，不阻挡。 五六米的距离，老人已经气喘吁吁。我也不说话，我单单陪着她。 院里的枣树上落了一只麻雀，不知为何她没回南方的家。隔壁的二层小楼开始掌起灯火，夜色也正吞下了半边天。 二嫂接着往外拖着步子，这时媳妇却迎着面从小卖部回来。 哎呀，涛你怎么让你奶奶出屋里来了？外面冷，娘咱回屋里吧。 二嫂不肯，但她做不了主。 这已不是她做主的日子了。 爷爷大二嫂好多岁，早就没了精神。多少年大大小小，一直是二嫂操持着。 去年的时候，我坐在炕头边，绕着问她年轻时候的故事。 她说她的一生就分为两部分，给大伙种地和给自己种地。前半段三十年，后半段三十年。 明明从北京赶过来，她却说这里更冷一些。村支书被打得藏在柜子底下，三千斤麦子换来的推车充了公，大雨下到把房子冲塌，夜不闭户，好冷。 二嫂说后来却是倒春寒。家乡的新媳妇，都凑不出一件体面衣裳。地里什么东西也不长。饿死的人排着队。 我问再后来呢？自己种总好些了吧？ 二嫂说自己种也要上交粮食给国家的。那年她推着小车，走了二十几里的土路，把麦子送到乡上。三十年了。 二嫂说这么多年看上去一直是我在做主支撑着这个家，但实际上我从来都没做过主，我对自己也做不了主，我对谁也做不了主。 我说还是我们这一代人幸福啊，赶上了好的时候。 二嫂说那只是看起来，长大了你就明白了。 然而我从来都长不大，二嫂却变老了。 二嫂老了，但从没老糊涂，也没装过糊涂，直到突然的疾病将糊涂的能力赐予给她。 回到屋里，二嫂就又安静地坐下来。电视里恰巧是场晚会，在希望的田野上。 夜幕已全然降临。猎户座的三星嵌在南面的而天空，月亮瘦成眉毛，挑在树枝上，除此之外，一片看不透的灰色将视野罩的密不透风。 我瞪着窗外，正出神，二嫂那边却哼了起来，摇起我的手。 呜呜声。奶奶又回到了回不去的小时候。 @ddlee 2017年2月","categories":[{"name":"随笔","slug":"随笔","permalink":"http://blog.ddlee.cn/categories/随笔/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"http://blog.ddlee.cn/tags/随笔/"}]},{"title":"谁会不厌其烦地安慰那无知的少年（一）","slug":"谁会不厌其烦地安慰那无知的少年-1","date":"2017-01-27T14:20:59.000Z","updated":"2017-04-02T17:48:33.517Z","comments":true,"path":"2017/01/27/谁会不厌其烦地安慰那无知的少年-1/","link":"","permalink":"http://blog.ddlee.cn/2017/01/27/谁会不厌其烦地安慰那无知的少年-1/","excerpt":"","text":"一个男孩要下过多少电影，才能称得上是一个男人？一只海鸥要飞过多少海洋，才能在柔柔的沙滩上安息？——鲍勃·迪伦，《答案在风中飘荡》 星星眨着眼，银河却不见。万家灯火散落在不遥远的远方，贪婪的夜色吞噬着视野，列车不紧不慢地刺破雾气的深不可测，卧铺床头的小台灯透过车窗温暖出朦胧一片，笼住返乡人的放松与期盼。 其实丁丁差点没赶上火车。亏得遇到老司机，路上没怎么堵。过检票口的时候，广播刚刚喊着“你所乘坐的班次已停止检票”。 火车终于安稳地行着。丁丁的心情也慢慢舒畅起来。 丁丁趴在铺上，翻看相册，回想这又一个人生七年。 小学到中学就是一趟火车，有起点也有终点，不慌不忙。大学是脱了轨的同一趟火车，东栽西撞，没有诗也到不了远方。 想到这里，丁丁下了铺，留意了一下安全锤的位置，然而，在回来时，他还是不可避免地被旁边的大叔注意到了。 嘿，小伙子，你也用Lumia 啊。 丁丁尴尬地讲，没，只是备用机，主力还是安卓。心想着竟然还被看出来了，不过正好，用Lumia不装逼，那跟咸鱼有什么区别。 大叔你做什么工作的呀。 大叔讲他是个半个码农，三倍的房奴，两个孩子的爹地，一个老婆坚实的依靠。 丁丁说自己是三个舍友的爸爸，五门课的开课赞助商，七个女生的备胎，九个社团的划水副总监。 大叔说你这就是我的Pro版啊，深交吗小伙子？ 丁丁说，好。 可这一开口，大叔就是从诗词歌赋到人生哲学。只不过，没有雪也没有月亮，我不是紫薇他也不叫尔康。 大叔并不大，现在在南京，江北一套房，鼓楼一套学区。两个儿子，大的刚上一年级，小的还不会撒谎。 自己公司年底出了状况，没能跟家人坐同一趟车回家。 大叔说自己本科数学，毕了业才发现自己卵没什么用。女朋友学计算机，早就找好了工作，自己只好考了研，后来拿了个硕士，主攻信号转发与缓存。 丁丁说我也数学。 大叔抿了抿嘴，嗯，有意思有意思。 大叔说那我给你介绍介绍考研经验吧。 丁丁说好啊好啊。 那年考研的形势很严峻，因为减招。 为了考研，大三那年寒假，我初五就从家里跑出来了。赶巧的是，那年跟今年一样，过年赶得好晚，我统共在家不到十天。 临走那天晚上，爸爸到单位值班，去之前又塞给我几百块钱，说穷家富路，但这种行为被我义正辞严地拒绝了。可爸爸走后，我泪湿眼底。 因为这一离开就又是半年。 考上大学第一年回家，奶奶跟我说你走后你爸来我这儿的时候哭了，说你跟小鸟一样飞走了。我说也是啊，我长大了，爸爸的一个时代也结束了呀，就在我报完到送他回去的那一刻。 那天在楼下值班室那里领钥匙，爸爸在一边摸着头笑，见我回头，他跟遇到喜欢的女生那样不好意思，红着脸。 爸爸的一个时代结束了呀。 还记得，我上小学那会儿，连午休都要家长签字确认的，还有作业也是，爸爸兢兢业业地把题都重新算一遍，马虎的地方狠狠批我一顿，这才用方方正正的钢笔给我签上“家长已检查”，现在我才知道，这叫“背书”。 那时候妈妈在一边儿踩着缝纫机，看点播台的我被爸爸叫过去，扭扭捏捏地摸着后脑勺，阳台上水仙开着，香味儿就飘到屋里来。 其实那时候的我才最懂事儿。那时我最大的梦想就是娶了班上最文静的女生，让妈妈少操点儿心。而她当时就是我的同桌，放学我们还一起走到灵石路的尽头，走过小酒馆的门口。后来四五年级，起了流言，我们就分了。 后来在外面求学，跟父母在一起的时间就越来越少了。那时候我最喜欢的时候是坐在大巴士高高的最后一排，靠窗，看路边的杨树一棵一棵闪过，我觉得我的人生康庄大道就在脚下一点一点伸展开来。 爸爸给我的支持也越来越少了。他不懂遗传平衡定律，找不到辅助线，也人脸识别不了虚拟语气。我的小小心思就像宇宙那般，无边地膨胀起来了。 高考就是碰到气球的那根针。我感觉自己是被发配到了南方，而且还被冻成了狗。 丁丁顺着说，南方确实冷的不行，尤其下雨天。 大叔说，你看，这些小事，我不说，就要一点一点埋葬在潺潺流去的岁月里了。 可我考研那年不懂事。我哭的时候，却觉得自己分分钟像个大人了，我早回去正是在做着那些英雄们不得不做的事儿。天将降大任于斯人矣。 为了呵护这个家，却要离开它。 浊酒一杯，家万里。 我觉得这就是我的燃情岁月。 后来研考上了，女朋友等了我三年，然后就媳妇也有了。后来我才知道燃情岁月才算刚刚开始。 丁丁蛮懂事，道，汪、汪、汪。 再后来，有了一室一厅，吉利帝豪，郊区的三室两厅，又因为堵车把车给卖了，再后来有了一个儿子，鼓楼的学区加户口房，又添了个儿子，就把爸妈接过来了。 这几年没有我特别想做的事儿。只有我需要做好的事儿。 两个小魔王，说实话我不觉得爸妈老年生活有多幸福。 不过多亏通了地铁，我每天八点半能到家，磕个瓜子，跟我爸聊聊我儿子和他儿子。 可是，小伙子，你知道吗？我考研那年，就是个愣头青。 那时候我对私人的时间有着近乎偏执的吝啬。我觉得自己独处的时间才是上天赐予的礼物。回家过年又烦又累，措不及防的应酬是对我神圣的私有时间的侵犯。所以，其实我早早就狠下心来，一定要早早的回学校。 我上车那天风声呼啸，暗云疾行，干燥的北风中赫赫抬起的，是我打车的一只大手。路两边白杨赤条条的，行人裹着衣，绷着脸。 风萧萧兮易水寒，众人向北我向南。 可是，小伙子，你知道吗？ 让男孩成为男人的，不是事业，是家业啊。 大叔突然不说了。他翻了个身，晚安。 丁丁也回过头，抹了眼睛，退了返程。 @ddlee 2017年1月","categories":[{"name":"随笔","slug":"随笔","permalink":"http://blog.ddlee.cn/categories/随笔/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"http://blog.ddlee.cn/tags/随笔/"}]},{"title":"小米3变身记","slug":"小米3变身记","date":"2016-09-22T17:40:00.000Z","updated":"2017-04-05T13:13:00.264Z","comments":true,"path":"2016/09/23/小米3变身记/","link":"","permalink":"http://blog.ddlee.cn/2016/09/23/小米3变身记/","excerpt":"","text":"Across the Great Wall we can reach every corner in the world.”（越过长城，走向世界） 1.缘起——我、小米、安卓和Android知乎上有个抖机灵的回答，问题是“Nexus 5 如果不使用 VPN，会有什么影响”，回答是“android 体验变成安卓体验”。感谢无所不能的墙，让Android也有了中国特色。 各家应用市场层出不穷，应用推广不择手段，申请权限多多益善，后台活动精彩不断。更不能忍的是，小米移除了Google的服务框架，无法从Play商店推动应用。为了用Sleep Cycle alarm clock, 我得用在线工具从Play商店获取链接，同步到云盘里，再从手机里打开.apk文件来安装。因为，百度搜索出的那个结果，应用中内置了烦人的广告。 终于，我投奔了IOS阵营，手中服役的小米3也就闲置。在一个并没有那么蛋疼的午后，我拿出数据线，对它说，It’s time. 注意：本系列不作为通用教程，只做经历分享。请移步相关论坛获取教程信息。 2.基础——是什么，为什么，怎么办是什么你一定听说过，有种技术叫刷机。你也一定听说过，还有种技术叫越狱。你更一定听说过，还有种技术叫FanQiang。 这三者有什么关系呢？ 在我看来，它们都关乎我们作为用户常常忽略的两个字——权限。 换言之，我们常常关注可以用手机干什么、可以上网浏览什么，却常常不去注意，我们本来有更多事可以做，有更多信息可以获取。 刷机意味着给手机重装系统，你获得的是选择硬件所运行系统的权利；越狱获得的是掌控某一操作系统的权利；而FanQiang，获得的则是“越过长城，走向世界”的权利。 中国第一封电子邮件的内容是：Across the Great Wall we can reach every corner in the world.”（越过长城，走向世界）。这是1987年9月14日从北京向海外发出的中国第一封电子邮件，揭开了中国人使用互联网的序幕。 来源：知乎 为什么因为无聊，因为好奇，因为喜欢，因为不满足，因为我们可以。 怎么办如果把刷机比作建造楼房，你所需要准备的就是知识（图纸）、刷机包（水泥、混凝土）、调试环境（吊塔）。 知识真正重要的知识，是关于知识的知识。拿到图纸不重要，重要的是学会如何看懂图纸。以我的经历，最耗费精力的部分不是学习教程，而是TROUBLE SHOOTING, 是如何解决出现的问题。 因此，绝对不要使用某些工具的“一键刷机功能”，它们不会告诉你问题出在哪。 请保证你对整个过程的绝对控制，保证你清楚到底在哪一步无法继续进行。 而为了看懂图纸，你需要准备好你的Google.它会是你最可靠的伙伴。 下面是图纸中可能涉及的内容，请搜索并结合某些通用刷机教程理解它们发挥的作用。 卡刷、线刷：两种刷机的操作方式（体位） Root：获取Android系统管理员的过程 OTA：On The Air， 一种系统更新方式 ROM包： 刷入手机ROM的系统软件包 Recovery Mode： Android系统的一种模式，常在此模式下进行刷机操作 Fastboot Mode： Android系统的一种模式，可在此模式下刷入自定义recovery ADB： Android Debug Bridge，用PC对Android系统进行USB调教所需的环境 CM： 一家著名的ROM制作方，现已改名Lineage OS Android M： Android系统的一个版本，现在是N（Nougat，7.0） GApps： Google服务全家桶，需要刷入系统分区，包括Play和GMS等服务 3.刷机——大致的步骤，常见的坑一个负责任的教程，大概会告诉你如下几个步骤 风险警示 备份数据 如何搭建ADB环境-PC 如何进入fastboot模式-手机 如何在ADB环境下，fastboot模式中刷入自定义recovery 如何利用recovery模式清除数据，刷入ROM包（和Gapps） 如何ROOT 一次蛋疼的刷机经历，常常会遇到这些坑 找到正确的Recovery和ROM包：一定要仔细比对型号，尽量选用开源机构制作的包 搭建ADB环境：要用到命令行（请慎重选用一件脚本，即.bat文件） 连接电脑与手机：Windows系统下需要硬件驱动（请注意型号） …… 4.资源——与你同行论坛与搜索引擎你会发现，手机厂商的官方论坛和XDA等论坛会很有帮助。但真正与你同行的，还是Google。 常用网址 TWRP，著名的自定义recovery GApps，Google全家桶 Xposed，著名开源框架 ADB Guide SuperSU，用于手机Root @ddlee","categories":[{"name":"Android","slug":"Android","permalink":"http://blog.ddlee.cn/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"http://blog.ddlee.cn/tags/Android/"}]},{"title":"数据分析在线学习资源(Personal Archive)","slug":"数据分析资源","date":"2016-08-07T11:58:31.000Z","updated":"2017-04-09T15:44:33.604Z","comments":true,"path":"2016/08/07/数据分析资源/","link":"","permalink":"http://blog.ddlee.cn/2016/08/07/数据分析资源/","excerpt":"","text":"数据分析方向的在线资源收集。 1.Some wonderful Tutorials Data Analysis Learning Path from Springboard The Open Source Data Science Masters 2. Basic2.1 DatabaseStanford’s Database course 2.2 AgrolthmsAlgrothms from Stanford via Coursera(using Java)Booksite hereAlgorithm with Python in GItHub 2.3 AlgebraHarvard’s Massive Parralle Algebra Course on iTunes U 2.4 StatisticsPrinceton’s Statistics One 2.5 Books Pattern Recognition and Machine Learning by Bishop The Elements of Statistical Learning 3. Python3.1 Scipy &amp; Pandas &amp; sklearn Scipy Lecture Notes Pandas Doc Pandas Cookbook sklearn Doc 3.2 Python MOOCsedX courseMITx: 6.00.2x Introduction to Computational Thinking and Data Science via edX Udacity Course Design of Computer Programs with Peter Novig Intro to Machine Learning (project oriented) Machine Learning: Unsupervised Learning 3.3 Books Python for Data Analysis by Wes McKinney Programming Collective Intelligence by Toby Segaran 4. R4.1 R MOOCsedX courseMIT’s The Analytics Edge JH Data Science Specilization via Coursera Statistical Inference Regression Model Practical Machine Learning Develop Data Science Product Stanford’s Statistical Learninghereand its text book An Introduction to Statistical Learning ISLAR 4.2 R Books R Graphics Cookbook by Winston Chang ggplot2 by Hadley Wickham R in Action by Robert I. Kabacoff 5. Big Data5.1 “Big” MOOCsUdacity CourseIntro to Hadoop and MapReduce from clourdera Coursera CourseMining Massive Datasets edX CourseXserise on Spark from BerkleyX 6. Capstone Project SITP Project Health Twitter Analysis via Coursolve 7. Additional Resource Harvard’s CS109 Course: Data Science Berkley’s CS61:The Structure and Interpretation of Computer Programs Probabilistic Graphical Models via Coursera Berkeley’s Datascience’s Documentation A Gallery of IPython Notebooks A collection of Data Science Learning materials in the form of IPython Notebooks Unsupervised Feature Learing and Deep Learning @ddlee","categories":[{"name":"Data Science","slug":"Data-Science","permalink":"http://blog.ddlee.cn/categories/Data-Science/"}],"tags":[{"name":"Data Science","slug":"Data-Science","permalink":"http://blog.ddlee.cn/tags/Data-Science/"},{"name":"Data","slug":"Data","permalink":"http://blog.ddlee.cn/tags/Data/"}]},{"title":"个性化你的Ubuntu-3：主题，插件以及桌面小工具","slug":"个性化你的Ubuntu-3：主题，插件以及桌面小工具","date":"2016-06-11T14:52:49.000Z","updated":"2017-04-05T13:13:04.420Z","comments":true,"path":"2016/06/11/个性化你的Ubuntu-3：主题，插件以及桌面小工具/","link":"","permalink":"http://blog.ddlee.cn/2016/06/11/个性化你的Ubuntu-3：主题，插件以及桌面小工具/","excerpt":"","text":"个性主题依赖于扩展User themes，分为GTK主题，shell主题和icon主题。 从gnome-look.org下载喜欢的主题（压缩文件）。 将下载的主题文件复制到用户文件夹 cd ~ mkdir .themes cp file_path_to_download_file ~/.themes 并使用unzip或tar xvzf命令解压，或者： sudo cp file_path_to_download_file /usr/local/themes/ 在gnome-tweak-tool的扩展User themes中选择主题。 推荐主题我使用的是Numix系列的主题（官网） Numix-GTK3 theme Numix-like GNOME Shell theme Numix-Circle Icons Numix开发者之一Satyajit Sahoo发布的GNOME shell theme:Gnome Shell - Elegance Colors 通过PPA安装 sudo apt-add-repository ppa:numix/ppa sudo apt-get update sudo apt-get install numix-gtk-theme sudo apt-get install numix-icon-theme-circle sudo add-apt-repository ppa:satyajit-happy/themes sudo apt-get update &amp;&amp; sudo apt-get install gnome-shell-theme-elegance-colors 扩展插件我当前使用的插件： hide dash：隐藏侧边的favorite栏 Pomotodo：番茄时钟 （荐）Clipboard indicator：剪贴板切换 ToDo.txt：待办事项整理 Places indicator：文件浏览器的快捷方式 Activities configurator: 当前活动程序管理 Alternatetab: alt-tab桌面切换 Applications menu：类似Windows下开始菜单 （荐）Drop down terminal：快捷启动终端 Netspeed：网速监控 Openweather：状态栏天气预报 Removable drive menu：弹出U盘等可移除硬件 （荐）Dynamic top bar：根据窗口颜色变换顶栏颜色 其他桌面工具DOCK推荐Cairo-Dock，效果如图，扩展性很高，自定义程度也很好。 CONKY：桌面监测工具推荐Conky，皮肤也有很多，效果如图。 本系列至此完结。欢迎入坑。 @ddlee 2016年6月","categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.ddlee.cn/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://blog.ddlee.cn/tags/Linux/"},{"name":"Gnome","slug":"Gnome","permalink":"http://blog.ddlee.cn/tags/Gnome/"}]},{"title":"个性化你的Ubuntu-2：GNOME安装与工具","slug":"个性化你的Ubuntu-2：GNOME安装与工具","date":"2016-06-02T14:19:50.000Z","updated":"2017-04-05T13:13:02.736Z","comments":true,"path":"2016/06/02/个性化你的Ubuntu-2：GNOME安装与工具/","link":"","permalink":"http://blog.ddlee.cn/2016/06/02/个性化你的Ubuntu-2：GNOME安装与工具/","excerpt":"","text":"GNOME安装从上一篇文章，大家可以看到，GNOME是一系列软件的集合，安装时可以有不同的取舍。对于Ubuntu用户来说，可以有以下两类体验GNOME的方式。（参考：GNOME installation） 1.Ubuntu GNOME（系统）Ubuntu GNOME是Ubuntu的一个发行版本（也称Ubuntu variants），就像Ubuntu和Fedora等都是GNU/Linux的发行版那样。Ubuntu GNOME不仅包含了Ubuntu的核心部分、GNOME的核心部分，还有一系列的标准应用。 Install from DVD如果可以接受重新安装系统，请到这里下载Ubuntu GNOME。 Install with current system你也可以通过安装metapackage，这样在安装GNOME桌面环境时，你的系统中未安装的标准应用也会被同时安装。 sudo apt-get install ubuntu-gnome-desktop 2.GNOME（仅桌面环境）The “real” GNOME标准的GNOME桌面环境，没有Ubuntu的特性（尽管我区分不出哪些是Ubuntu提供的），也不安装附加的标准应用： sudo apt-get install gnome The minimux GNOMEGNOME的核心部分，不安装附加的标准应用： sudo apt-get install gnome-core GNOME shell仅安装GNOME的图形界面：sudo apt-get install gnome-shell 你还需要：sudo apt-get install gnome-session 注意在同一系统上安装不同的桌面环境可能会造成一些意料不到的问题（如锁屏界面丢失），最推荐的方案还是重新安装Ubuntu GNOME，其次，可以安装ubuntu-gnome-desktop。 使用新的桌面环境安装完毕后，重启，可在登录界面选择桌面环境。 GNOME配置工具：gnome-tweak-tool想要充分个性化GNOME桌面环境，扩展GNOME的功能，你还需要安装GNOME的配置工具：gnome tweak tool sudo apt-get install gnome-tweak-tool 利用gnome tweak tool，你可以管理桌面主题、调整窗口特性、调整显示字体、加载GNOME扩展、管理开机自启程序等等。 扩展插件在Ubuntu上，要调整桌面主题，可没有Windows上鼠标右击一下那么简单。你要先安装上面的tweak tool，然后有人告诉你需要User theme扩展插件，而你跑到extensions.gnome.org，遇到的却是这个： 我明明装了GNOME的啊！ 这是因为，extensions.gnome.org需要与浏览器通信，调用click-to-play的功能，我们需要安装GNOMNE shell intergration这个插件。 Chrome用户利用PPAsudo add-apt-repository ppa:ne0sight/chrome-gnome-shell sudo apt-get update sudo apt-get install chrome-gnome-shell 通过Chrome Web Store:GNOME Shell integration可能需要通过CMake安装native connector,请参考这一页面。 FireFox用户使用FireFox访问extensions.gnome.org时会有运行GNOME shell integration的通知，允许运行后刷新即可。 更多信息，请参考这一页面 安装好tweak-tool后，祝贺你已经打开了新世界的大门。下篇文章是关于扩展插件的推荐，欢迎继续阅读。 @ddlee","categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.ddlee.cn/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://blog.ddlee.cn/tags/Linux/"},{"name":"Gnome","slug":"Gnome","permalink":"http://blog.ddlee.cn/tags/Gnome/"}]},{"title":"个性化你的Ubuntu-1：GNOME桌面环境","slug":"个性化你的Ubuntu-1：GNOME桌面环境","date":"2016-05-30T11:12:10.000Z","updated":"2017-04-05T13:13:06.908Z","comments":true,"path":"2016/05/30/个性化你的Ubuntu-1：GNOME桌面环境/","link":"","permalink":"http://blog.ddlee.cn/2016/05/30/个性化你的Ubuntu-1：GNOME桌面环境/","excerpt":"","text":"我与Ubuntu我最初是Windows98用户，再到Windows2003,Windows XP,Windows 7,上了大学后用Windows 8.1,Windows 10（想不到竟然能列这么长；我从没用过Windows Vista,不知道那是什么东西），我很喜欢8.1和10的开始屏幕和动态磁贴。非常偶然的机会，我在CS50的课程中接触了GNU/Linux，才知道，原来在MS Windows和Mac OSＸ之外，还有一个GNU/Linux。换完SSD，学会了装操作系统，我便踏上了折腾GNU/Linux的不归路。 曾经被一个软院的同学安利Red Hat系的Fedora（尽管他现在已经投入了MacBook的怀抱）,普及各种内核之类的知识。然而，我只想安静的用它上上网，进行科学计算，并没有深入到考虑系统底层的需求层次。我还是安心地用Ubuntu吧。我也推荐第一次尝试GNU/Linux系统的小白从Ubuntu开始，相信我,askubuntu.com和stackoverflow.com会解决你的大部分问题的。 个性化你的Ubuntu（一）：GNOME桌面环境相信不少读者都是从Microsoft Windows转到GNU/Linux阵营的,早就习惯了用户图形界面。但是，配合桌面环境、主题和一些插件和软件，Ubuntu照样可以很酷炫。 什么是GNOME（大脚丫为什么这么大。。。） GNOME(pronounced /ɡˈnoʊm/ or /ˈnoʊm/) 最初是GNU Network Object Model Environment的缩写，但这一缩写已不再沿用（更多历史情况请参见这里）。 我们所说的GNOME，通常指的是由The GNOME Project开发的运行于Linux之上的桌面环境。 我们每天面对的，并不是全部的Microft Windows/OS X/Linux系统，而是系统提供给我们的人机接口，而桌面环境，则是统一在同一图形用户接口（GUI）之下的一揽子软件（X Window Manager, File manager, Terminal emulator, Text editor, Image viewer, E-mail client等）。 来源 Ubuntu自带的桌面环境是Unity（图形外壳）,其他流行的桌面环境还有KDE,Xfce。但我们要谈的是GNOME。 什么是X window system要谈Unix-like系统上的图形界面，就不得不提X Window System。那么，什么是X? The X Window System, commonly referred to merely as X, is a highly configurable, cross-platform, complete and free client-server system for managing graphical user interfaces (GUIs) on single computers and on networks of computers. (X窗口系统，通常简称为X，是用于管理在单个计算机和计算机网络上运行的图形用户界面（GUI）一个高度可配置的，跨平台，完整的，自由的客户端-服务器系统。） 来源：LINFO 我们试着通过X能够干什么来理解一下这句话。 X是一组规则、一套方法。它提供了从硬件（键鼠）接受用户输入、创建图形窗口、画出直线、位图等基本的图形功能（图形引擎）。 X实现了客户端-服务器的机制。通过划分Server和Client，X既能在本地计算机上运行，也能在计算计算机网络中运行。 X与操作系统独立。X可以理解为运行在操作系统之上的一套软件。如果不需要GUI，完全可以不用安装X。而在Microsoft Windows和OS X中，图形引擎是操作系统的一部分。 X Window System的结构如图。 GNOME &amp; XGNOME和X Window System是什么关系？桌面环境可以理解为一系列X client的集合，其中最重要的组件是X Window Manager。由于X Window System的client-server机制，各client之间是相对独立的，这时，需要一个特殊的client管理其他client，将他们统一在一个框架之下，这就是X Window Manager。来源 而GNOME另一个重要的组成部分是GNOME shell，它是一个图形外壳程序，也就是我们要面对的接口。 跟GNOME相关的其他组件、库、概念 GTK+：GIMP Widget toolkits，GNOME基于的GUI工具箱。KDE则基于Qt。 Display Manager:图形用户登陆管理器，为用户提供登陆界面，与session manager通信，开启新的session。GNOME使用的是GDM。 Metacity：GNOME 2使用的window manager，GNOME 3使用的是Mutter。KDE使用的是KWin。 Wayland:与X Window System对应，也是一种窗口系统 我现在的桌面 我不喜欢双击桌面图标来启动程序，更多用的是Dock和全局搜索，所以，桌面上“什么都没有”。 桌面的壁纸是电影 飞屋环游记 的海报，使用了Numix系列的主题和图标。 下方Dock使用的程序是Cairo-Dock，桌面右方运行的程序是Conky，用来监测系统运行情况和提供天气信息，上方的Topbar里添加了许多GNOME的扩展应用。 接下来的两篇文章将介绍Gnome的安装与扩展推荐，欢迎继续阅读，撒花。 @ddlee","categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.ddlee.cn/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://blog.ddlee.cn/tags/Linux/"},{"name":"Gnome","slug":"Gnome","permalink":"http://blog.ddlee.cn/tags/Gnome/"}]}]}